
otx2_bpf_arch_insn.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <build_prologue>:

/* Tail call offset to jump into */
#define PROLOGUE_OFFSET 7

int build_prologue(struct otx2_bpf_arch_ctx *ctx, struct bpf_prog *prog)
{
       0:	a9be7bfd 	stp	x29, x30, [sp, #-32]!
	 *                          low
	 *
	 */

	/* Save FP and LR registers to stay align with ARM64 AAPCS */
	emit(A64_PUSH(A64_FP, A64_LR, A64_SP), ctx);
       4:	52800065 	mov	w5, #0x3                   	// #3
       8:	52800024 	mov	w4, #0x1                   	// #1
{
       c:	910003fd 	mov	x29, sp
      10:	a90153f3 	stp	x19, x20, [sp, #16]
      14:	aa0003f3 	mov	x19, x0
      18:	aa0103f4 	mov	x20, x1
	emit(A64_PUSH(A64_FP, A64_LR, A64_SP), ctx);
      1c:	128001e3 	mov	w3, #0xfffffff0            	// #-16
      20:	528003e2 	mov	w2, #0x1f                  	// #31
      24:	528003c1 	mov	w1, #0x1e                  	// #30
      28:	528003a0 	mov	w0, #0x1d                  	// #29
      2c:	94000000 	bl	0 <aarch64_insn_gen_load_store_pair>
      30:	2a0003e7 	mov	w7, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
      34:	39410265 	ldrb	w5, [x19, #64]
	emit(A64_MOV(1, A64_FP, A64_SP), ctx);
      38:	52800023 	mov	w3, #0x1                   	// #1
      3c:	52800004 	mov	w4, #0x0                   	// #0
      40:	52800002 	mov	w2, #0x0                   	// #0
	ctx->bpf2bi_cnt++;
      44:	0b0300a6 	add	w6, w5, w3
	emit(A64_MOV(1, A64_FP, A64_SP), ctx);
      48:	528003e1 	mov	w1, #0x1f                  	// #31
      4c:	528003a0 	mov	w0, #0x1d                  	// #29
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
      50:	b825da67 	str	w7, [x19, w5, sxtw #2]
	ctx->bpf2bi_cnt++;
      54:	39010266 	strb	w6, [x19, #64]
	emit(A64_MOV(1, A64_FP, A64_SP), ctx);
      58:	94000000 	bl	0 <aarch64_insn_gen_add_sub_imm>
      5c:	2a0003e8 	mov	w8, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
      60:	39410266 	ldrb	w6, [x19, #64]

	/* Save callee-saved registers */
	emit(A64_PUSH(r6, r7, A64_SP), ctx);
      64:	52800024 	mov	w4, #0x1                   	// #1
      68:	52800065 	mov	w5, #0x3                   	// #3
      6c:	128001e3 	mov	w3, #0xfffffff0            	// #-16
	ctx->bpf2bi_cnt++;
      70:	0b0400c7 	add	w7, w6, w4
	emit(A64_PUSH(r6, r7, A64_SP), ctx);
      74:	528003e2 	mov	w2, #0x1f                  	// #31
      78:	52800281 	mov	w1, #0x14                  	// #20
      7c:	52800260 	mov	w0, #0x13                  	// #19
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
      80:	b826da68 	str	w8, [x19, w6, sxtw #2]
	ctx->bpf2bi_cnt++;
      84:	39010267 	strb	w7, [x19, #64]
	emit(A64_PUSH(r6, r7, A64_SP), ctx);
      88:	94000000 	bl	0 <aarch64_insn_gen_load_store_pair>
      8c:	2a0003e8 	mov	w8, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
      90:	39410266 	ldrb	w6, [x19, #64]
	emit(A64_PUSH(r8, r9, A64_SP), ctx);
      94:	52800024 	mov	w4, #0x1                   	// #1
      98:	52800065 	mov	w5, #0x3                   	// #3
      9c:	128001e3 	mov	w3, #0xfffffff0            	// #-16
	ctx->bpf2bi_cnt++;
      a0:	0b0400c7 	add	w7, w6, w4
	emit(A64_PUSH(r8, r9, A64_SP), ctx);
      a4:	528003e2 	mov	w2, #0x1f                  	// #31
      a8:	528002c1 	mov	w1, #0x16                  	// #22
      ac:	528002a0 	mov	w0, #0x15                  	// #21
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
      b0:	b826da68 	str	w8, [x19, w6, sxtw #2]
	ctx->bpf2bi_cnt++;
      b4:	39010267 	strb	w7, [x19, #64]
	emit(A64_PUSH(r8, r9, A64_SP), ctx);
      b8:	94000000 	bl	0 <aarch64_insn_gen_load_store_pair>
      bc:	2a0003e8 	mov	w8, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
      c0:	39410266 	ldrb	w6, [x19, #64]
	emit(A64_PUSH(fp, tcc, A64_SP), ctx);
      c4:	52800024 	mov	w4, #0x1                   	// #1
      c8:	52800065 	mov	w5, #0x3                   	// #3
      cc:	128001e3 	mov	w3, #0xfffffff0            	// #-16
	ctx->bpf2bi_cnt++;
      d0:	0b0400c7 	add	w7, w6, w4
	emit(A64_PUSH(fp, tcc, A64_SP), ctx);
      d4:	528003e2 	mov	w2, #0x1f                  	// #31
      d8:	52800341 	mov	w1, #0x1a                  	// #26
      dc:	52800320 	mov	w0, #0x19                  	// #25
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
      e0:	b826da68 	str	w8, [x19, w6, sxtw #2]
	ctx->bpf2bi_cnt++;
      e4:	39010267 	strb	w7, [x19, #64]
	emit(A64_PUSH(fp, tcc, A64_SP), ctx);
      e8:	94000000 	bl	0 <aarch64_insn_gen_load_store_pair>
      ec:	2a0003e7 	mov	w7, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
      f0:	39410265 	ldrb	w5, [x19, #64]

	/* Set up BPF prog stack base register */
	emit(A64_MOV(1, fp, A64_SP), ctx);
      f4:	52800023 	mov	w3, #0x1                   	// #1
      f8:	52800004 	mov	w4, #0x0                   	// #0
      fc:	52800002 	mov	w2, #0x0                   	// #0
	ctx->bpf2bi_cnt++;
     100:	0b0300a6 	add	w6, w5, w3
	emit(A64_MOV(1, fp, A64_SP), ctx);
     104:	528003e1 	mov	w1, #0x1f                  	// #31
     108:	52800320 	mov	w0, #0x19                  	// #25
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     10c:	b825da67 	str	w7, [x19, w5, sxtw #2]
	ctx->bpf2bi_cnt++;
     110:	39010266 	strb	w6, [x19, #64]
	emit(A64_MOV(1, fp, A64_SP), ctx);
     114:	94000000 	bl	0 <aarch64_insn_gen_add_sub_imm>
     118:	2a0003e7 	mov	w7, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     11c:	39410265 	ldrb	w5, [x19, #64]

//	if (!ebpf_from_cbpf) {
	if (1) {
		/* Initialize tail_call_cnt */
		emit(A64_MOVZ(1, tcc, 0, 0), ctx);
     120:	52800023 	mov	w3, #0x1                   	// #1
     124:	52800004 	mov	w4, #0x0                   	// #0
     128:	52800002 	mov	w2, #0x0                   	// #0
	ctx->bpf2bi_cnt++;
     12c:	0b0300a6 	add	w6, w5, w3
		emit(A64_MOVZ(1, tcc, 0, 0), ctx);
     130:	52800001 	mov	w1, #0x0                   	// #0
     134:	52800340 	mov	w0, #0x1a                  	// #26
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     138:	b825da67 	str	w7, [x19, w5, sxtw #2]
	ctx->bpf2bi_cnt++;
     13c:	39010266 	strb	w6, [x19, #64]
		emit(A64_MOVZ(1, tcc, 0, 0), ctx);
     140:	94000000 	bl	0 <aarch64_insn_gen_movewide>
     144:	2a0003e6 	mov	w6, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     148:	39410262 	ldrb	w2, [x19, #64]
	}

	stack_size = STACK_ALIGN(prog->aux->stack_depth);

	/* Set up function call stack */
	emit(A64_SUB_I(1, A64_SP, A64_SP, stack_size), ctx);
     14c:	52800024 	mov	w4, #0x1                   	// #1
     150:	528003e1 	mov	w1, #0x1f                  	// #31
     154:	2a0403e3 	mov	w3, w4
	ctx->bpf2bi_cnt++;
     158:	0b040045 	add	w5, w2, w4
	emit(A64_SUB_I(1, A64_SP, A64_SP, stack_size), ctx);
     15c:	2a0103e0 	mov	w0, w1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     160:	b822da66 	str	w6, [x19, w2, sxtw #2]
	ctx->bpf2bi_cnt++;
     164:	39010265 	strb	w5, [x19, #64]
	stack_size = STACK_ALIGN(prog->aux->stack_depth);
     168:	f9401282 	ldr	x2, [x20, #32]
     16c:	b9401442 	ldr	w2, [x2, #20]
     170:	11003c42 	add	w2, w2, #0xf
	emit(A64_SUB_I(1, A64_SP, A64_SP, stack_size), ctx);
     174:	121c6c42 	and	w2, w2, #0xfffffff0
     178:	94000000 	bl	0 <aarch64_insn_gen_add_sub_imm>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     17c:	39410261 	ldrb	w1, [x19, #64]
	emit(A64_SUB_I(1, A64_SP, A64_SP, stack_size), ctx);
     180:	2a0003e3 	mov	w3, w0
	return 0;
}
     184:	52800000 	mov	w0, #0x0                   	// #0
	ctx->bpf2bi_cnt++;
     188:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     18c:	b821da63 	str	w3, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     190:	39010262 	strb	w2, [x19, #64]
}
     194:	a94153f3 	ldp	x19, x20, [sp, #16]
     198:	a8c27bfd 	ldp	x29, x30, [sp], #32
     19c:	d65f03c0 	ret

00000000000001a0 <build_epilogue>:
}

#endif

void build_epilogue(struct otx2_bpf_arch_ctx *ctx, struct bpf_prog *prog)
{
     1a0:	a9be7bfd 	stp	x29, x30, [sp, #-32]!
     1a4:	aa0103e2 	mov	x2, x1
	const u8 r9 = bpf2a64[BPF_REG_9];
	const u8 fp = bpf2a64[BPF_REG_FP];
	int stack_size = STACK_ALIGN(prog->aux->stack_depth);

	/* We're done with BPF stack */
	emit(A64_ADD_I(1, A64_SP, A64_SP, stack_size), ctx);
     1a8:	52800004 	mov	w4, #0x0                   	// #0
{
     1ac:	910003fd 	mov	x29, sp
     1b0:	f9000bf3 	str	x19, [sp, #16]
     1b4:	aa0003f3 	mov	x19, x0
	emit(A64_ADD_I(1, A64_SP, A64_SP, stack_size), ctx);
     1b8:	528003e1 	mov	w1, #0x1f                  	// #31
     1bc:	52800023 	mov	w3, #0x1                   	// #1
	int stack_size = STACK_ALIGN(prog->aux->stack_depth);
     1c0:	f9401042 	ldr	x2, [x2, #32]
	emit(A64_ADD_I(1, A64_SP, A64_SP, stack_size), ctx);
     1c4:	2a0103e0 	mov	w0, w1
	int stack_size = STACK_ALIGN(prog->aux->stack_depth);
     1c8:	b9401442 	ldr	w2, [x2, #20]
     1cc:	11003c42 	add	w2, w2, #0xf
	emit(A64_ADD_I(1, A64_SP, A64_SP, stack_size), ctx);
     1d0:	121c6c42 	and	w2, w2, #0xfffffff0
     1d4:	94000000 	bl	0 <aarch64_insn_gen_add_sub_imm>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     1d8:	39410266 	ldrb	w6, [x19, #64]

	/* Restore fs (x25) and x26 */
	emit(A64_POP(fp, A64_R(26), A64_SP), ctx);
     1dc:	52800024 	mov	w4, #0x1                   	// #1
     1e0:	52800085 	mov	w5, #0x4                   	// #4
     1e4:	52800203 	mov	w3, #0x10                  	// #16
	ctx->bpf2bi_cnt++;
     1e8:	0b0400c7 	add	w7, w6, w4
	emit(A64_POP(fp, A64_R(26), A64_SP), ctx);
     1ec:	528003e2 	mov	w2, #0x1f                  	// #31
     1f0:	52800341 	mov	w1, #0x1a                  	// #26
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     1f4:	b826da60 	str	w0, [x19, w6, sxtw #2]
	emit(A64_POP(fp, A64_R(26), A64_SP), ctx);
     1f8:	52800320 	mov	w0, #0x19                  	// #25
	ctx->bpf2bi_cnt++;
     1fc:	39010267 	strb	w7, [x19, #64]
	emit(A64_POP(fp, A64_R(26), A64_SP), ctx);
     200:	94000000 	bl	0 <aarch64_insn_gen_load_store_pair>
     204:	2a0003e8 	mov	w8, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     208:	39410266 	ldrb	w6, [x19, #64]

	/* Restore callee-saved register */
	emit(A64_POP(r8, r9, A64_SP), ctx);
     20c:	52800024 	mov	w4, #0x1                   	// #1
     210:	52800085 	mov	w5, #0x4                   	// #4
     214:	52800203 	mov	w3, #0x10                  	// #16
	ctx->bpf2bi_cnt++;
     218:	0b0400c7 	add	w7, w6, w4
	emit(A64_POP(r8, r9, A64_SP), ctx);
     21c:	528003e2 	mov	w2, #0x1f                  	// #31
     220:	528002c1 	mov	w1, #0x16                  	// #22
     224:	528002a0 	mov	w0, #0x15                  	// #21
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     228:	b826da68 	str	w8, [x19, w6, sxtw #2]
	ctx->bpf2bi_cnt++;
     22c:	39010267 	strb	w7, [x19, #64]
	emit(A64_POP(r8, r9, A64_SP), ctx);
     230:	94000000 	bl	0 <aarch64_insn_gen_load_store_pair>
     234:	2a0003e8 	mov	w8, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     238:	39410266 	ldrb	w6, [x19, #64]
	emit(A64_POP(r6, r7, A64_SP), ctx);
     23c:	52800024 	mov	w4, #0x1                   	// #1
     240:	52800085 	mov	w5, #0x4                   	// #4
     244:	52800203 	mov	w3, #0x10                  	// #16
	ctx->bpf2bi_cnt++;
     248:	0b0400c7 	add	w7, w6, w4
	emit(A64_POP(r6, r7, A64_SP), ctx);
     24c:	528003e2 	mov	w2, #0x1f                  	// #31
     250:	52800281 	mov	w1, #0x14                  	// #20
     254:	52800260 	mov	w0, #0x13                  	// #19
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     258:	b826da68 	str	w8, [x19, w6, sxtw #2]
	ctx->bpf2bi_cnt++;
     25c:	39010267 	strb	w7, [x19, #64]
	emit(A64_POP(r6, r7, A64_SP), ctx);
     260:	94000000 	bl	0 <aarch64_insn_gen_load_store_pair>
     264:	2a0003e8 	mov	w8, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     268:	39410266 	ldrb	w6, [x19, #64]

	/* Restore FP/LR registers */
	emit(A64_POP(A64_FP, A64_LR, A64_SP), ctx);
     26c:	52800024 	mov	w4, #0x1                   	// #1
     270:	52800085 	mov	w5, #0x4                   	// #4
     274:	52800203 	mov	w3, #0x10                  	// #16
	ctx->bpf2bi_cnt++;
     278:	0b0400c7 	add	w7, w6, w4
	emit(A64_POP(A64_FP, A64_LR, A64_SP), ctx);
     27c:	528003e2 	mov	w2, #0x1f                  	// #31
     280:	528003c1 	mov	w1, #0x1e                  	// #30
     284:	528003a0 	mov	w0, #0x1d                  	// #29
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     288:	b826da68 	str	w8, [x19, w6, sxtw #2]
	ctx->bpf2bi_cnt++;
     28c:	39010267 	strb	w7, [x19, #64]
	emit(A64_POP(A64_FP, A64_LR, A64_SP), ctx);
     290:	94000000 	bl	0 <aarch64_insn_gen_load_store_pair>
     294:	2a0003e7 	mov	w7, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     298:	39410265 	ldrb	w5, [x19, #64]

	/* Set return value */
	emit(A64_MOV(1, A64_R(0), r0), ctx);
     29c:	52800023 	mov	w3, #0x1                   	// #1
     2a0:	52800004 	mov	w4, #0x0                   	// #0
     2a4:	52800002 	mov	w2, #0x0                   	// #0
	ctx->bpf2bi_cnt++;
     2a8:	0b0300a6 	add	w6, w5, w3
	emit(A64_MOV(1, A64_R(0), r0), ctx);
     2ac:	528000e1 	mov	w1, #0x7                   	// #7
     2b0:	52800000 	mov	w0, #0x0                   	// #0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     2b4:	b825da67 	str	w7, [x19, w5, sxtw #2]
	ctx->bpf2bi_cnt++;
     2b8:	39010266 	strb	w6, [x19, #64]
	emit(A64_MOV(1, A64_R(0), r0), ctx);
     2bc:	94000000 	bl	0 <aarch64_insn_gen_add_sub_imm>
     2c0:	2a0003e4 	mov	w4, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     2c4:	39410262 	ldrb	w2, [x19, #64]

	emit(A64_RET(A64_LR), ctx);
     2c8:	52800041 	mov	w1, #0x2                   	// #2
     2cc:	528003c0 	mov	w0, #0x1e                  	// #30
	ctx->bpf2bi_cnt++;
     2d0:	11000443 	add	w3, w2, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     2d4:	b822da64 	str	w4, [x19, w2, sxtw #2]
	ctx->bpf2bi_cnt++;
     2d8:	39010263 	strb	w3, [x19, #64]
	emit(A64_RET(A64_LR), ctx);
     2dc:	94000000 	bl	0 <aarch64_insn_gen_branch_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     2e0:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     2e4:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     2e8:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     2ec:	39010262 	strb	w2, [x19, #64]
}
     2f0:	f9400bf3 	ldr	x19, [sp, #16]
     2f4:	a8c27bfd 	ldp	x29, x30, [sp], #32
     2f8:	d65f03c0 	ret
     2fc:	d503201f 	nop

0000000000000300 <build_insn>:
 * >0 - successfully JITed a 16-byte eBPF instruction.
 * <0 - failed to JIT.
 */
int build_insn(const struct bpf_insn *insn, struct otx2_bpf_arch_ctx *ctx,
		      bool extra_pass, u64 load_addr, struct otx2_bpf_prog *p)
{
     300:	a9ba7bfd 	stp	x29, x30, [sp, #-96]!
	const u8 code = insn->code;
	const u8 dst = bpf2a64[insn->dst_reg];
     304:	90000002 	adrp	x2, 0 <build_prologue>
     308:	91000042 	add	x2, x2, #0x0
{
     30c:	910003fd 	mov	x29, sp
     310:	a90153f3 	stp	x19, x20, [sp, #16]
	const s32 imm = insn->imm;
	struct otx2_bpf_insn *oinsn = (struct otx2_bpf_insn *)ctx;

	const int i = oinsn->idx;

	const bool is64 = BPF_CLASS(code) == BPF_ALU64 ||
     314:	528000a6 	mov	w6, #0x5                   	// #5
{
     318:	aa0103f3 	mov	x19, x1
     31c:	a9025bf5 	stp	x21, x22, [sp, #32]
     320:	aa0303e7 	mov	x7, x3
     324:	a90363f7 	stp	x23, x24, [sp, #48]
     328:	a9046bf9 	stp	x25, x26, [sp, #64]
int build_insn(const struct bpf_insn *insn, struct otx2_bpf_arch_ctx *ctx,
     32c:	39400405 	ldrb	w5, [x0, #1]
	const u8 code = insn->code;
     330:	39400014 	ldrb	w20, [x0]
	const u8 dst = bpf2a64[insn->dst_reg];
     334:	92400ca8 	and	x8, x5, #0xf
	const s16 off = insn->off;
     338:	79c00418 	ldrsh	w24, [x0, #2]
	const u8 src = bpf2a64[insn->src_reg];
     33c:	d3441ca5 	ubfx	x5, x5, #4, #4
	const bool is64 = BPF_CLASS(code) == BPF_ALU64 ||
     340:	0a060281 	and	w1, w20, w6
     344:	6b06003f 	cmp	w1, w6
     348:	51001283 	sub	w3, w20, #0x4
	const u8 dst = bpf2a64[insn->dst_reg];
     34c:	b8687855 	ldr	w21, [x2, x8, lsl #2]
	const bool is64 = BPF_CLASS(code) == BPF_ALU64 ||
     350:	1a9f17f7 	cset	w23, eq  // eq = none
	const u8 src = bpf2a64[insn->src_reg];
     354:	b8657859 	ldr	w25, [x2, x5, lsl #2]
	const s32 imm = insn->imm;
     358:	b9400416 	ldr	w22, [x0, #4]
	}							\
} while (0)
#define check_imm19(imm) check_imm(19, imm)
#define check_imm26(imm) check_imm(26, imm)

	switch (code) {
     35c:	7103c47f 	cmp	w3, #0xf1
     360:	54000189 	b.ls	390 <build_insn+0x90>  // b.plast
			emit(A64_ADD(isdw, tmp2, tmp2, src), ctx);
			emit(A64_STXR(isdw, tmp2, reg, tmp3), ctx);
			jmp_offset = -3;
			check_imm19(jmp_offset);
			emit(A64_CBNZ(0, tmp3, jmp_offset), ctx);
		}
     364:	90000002 	adrp	x2, 0 <build_prologue>
		break;
     368:	128002b6 	mov	w22, #0xffffffea            	// #-22
		}
     36c:	39400040 	ldrb	w0, [x2]
     370:	3400c2c0 	cbz	w0, 1bc8 <build_insn+0x18c8>

	default:
		pr_err_once("unknown opcode %02x\n", code);
		return -EINVAL;
     374:	2a1603e0 	mov	w0, w22
     378:	a94153f3 	ldp	x19, x20, [sp, #16]
     37c:	a9425bf5 	ldp	x21, x22, [sp, #32]
     380:	a94363f7 	ldp	x23, x24, [sp, #48]
     384:	a9446bf9 	ldp	x25, x26, [sp, #64]
     388:	a8c67bfd 	ldp	x29, x30, [sp], #96
     38c:	d65f03c0 	ret
     390:	90000002 	adrp	x2, 0 <build_prologue>
     394:	121d069a 	and	w26, w20, #0x18
     398:	91000042 	add	x2, x2, #0x0
     39c:	78635842 	ldrh	w2, [x2, w3, uxtw #1]
     3a0:	10000063 	adr	x3, 3ac <build_insn+0xac>
     3a4:	8b22a862 	add	x2, x3, w2, sxth #2
     3a8:	d61f0040 	br	x2
		pr_err_once("unknown opcode %02x\n", code);
     3ac:	52800016 	mov	w22, #0x0                   	// #0
     3b0:	17fffff1 	b	374 <build_insn+0x74>
		emit(A64_CMP(is64, dst, src), ctx);
     3b4:	2a1703e4 	mov	w4, w23
     3b8:	12001f22 	and	w2, w25, #0xff
     3bc:	12001ea1 	and	w1, w21, #0xff
     3c0:	52800065 	mov	w5, #0x3                   	// #3
     3c4:	52800003 	mov	w3, #0x0                   	// #0
     3c8:	528003e0 	mov	w0, #0x1f                  	// #31
     3cc:	94000000 	bl	0 <aarch64_insn_gen_add_sub_shifted_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     3d0:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     3d4:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     3d8:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     3dc:	39010262 	strb	w2, [x19, #64]
		switch (BPF_OP(code)) {
     3e0:	121c0e80 	and	w0, w20, #0xf0
     3e4:	7101c01f 	cmp	w0, #0x70
     3e8:	54009e40 	b.eq	17b0 <build_insn+0x14b0>  // b.none
     3ec:	54007428 	b.hi	1270 <build_insn+0xf70>  // b.pmore
     3f0:	7100c01f 	cmp	w0, #0x30
     3f4:	54007a00 	b.eq	1334 <build_insn+0x1034>  // b.none
     3f8:	540072e9 	b.ls	1254 <build_insn+0xf54>  // b.plast
     3fc:	7101801f 	cmp	w0, #0x60
     400:	540075c0 	b.eq	12b8 <build_insn+0xfb8>  // b.none
     404:	128001b6 	mov	w22, #0xfffffff2            	// #-14
     408:	54fffb68 	b.hi	374 <build_insn+0x74>  // b.pmore
     40c:	121b0a94 	and	w20, w20, #0xe0
     410:	7101029f 	cmp	w20, #0x40
     414:	54fffb01 	b.ne	374 <build_insn+0x74>  // b.any
     418:	52800022 	mov	w2, #0x1                   	// #1
     41c:	d503201f 	nop
		emit(A64_B_(jmp_cond, jmp_offset), ctx);
     420:	531e7701 	lsl	w1, w24, #2
     424:	d2800000 	mov	x0, #0x0                   	// #0
		pr_err_once("unknown opcode %02x\n", code);
     428:	52800016 	mov	w22, #0x0                   	// #0
		emit(A64_B_(jmp_cond, jmp_offset), ctx);
     42c:	93407c21 	sxtw	x1, w1
     430:	94000000 	bl	0 <aarch64_insn_gen_cond_branch_imm>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     434:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     438:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     43c:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     440:	39010262 	strb	w2, [x19, #64]
}
     444:	17ffffcc 	b	374 <build_insn+0x74>
	u16 hi = val >> 16;
     448:	13107eda 	asr	w26, w22, #16
     44c:	53107ed9 	lsr	w25, w22, #16
	if (hi & 0x8000) {
     450:	36f89636 	tbz	w22, #31, 1714 <build_insn+0x1414>
     454:	f9002bfb 	str	x27, [sp, #80]
		if (hi == 0xffff) {
     458:	529ffffa 	mov	w26, #0xffff                	// #65535
	u16 lo = val & 0xffff;
     45c:	12003edb 	and	w27, w22, #0xffff
		if (hi == 0xffff) {
     460:	6b1a033f 	cmp	w25, w26
     464:	5400a540 	b.eq	190c <build_insn+0x160c>  // b.none
			emit(A64_MOVN(is64, reg, (u16)~hi, 16), ctx);
     468:	2a3903e1 	mvn	w1, w25
     46c:	52800202 	mov	w2, #0x10                  	// #16
     470:	12003c21 	and	w1, w1, #0xffff
     474:	2a1703e3 	mov	w3, w23
     478:	52800044 	mov	w4, #0x2                   	// #2
     47c:	52800140 	mov	w0, #0xa                   	// #10
     480:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     484:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     488:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     48c:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     490:	39010262 	strb	w2, [x19, #64]
			if (lo != 0xffff)
     494:	6b1a037f 	cmp	w27, w26
     498:	5400aea0 	b.eq	1a6c <build_insn+0x176c>  // b.none
				emit(A64_MOVK(is64, reg, lo, 0), ctx);
     49c:	12003ec1 	and	w1, w22, #0xffff
     4a0:	52800024 	mov	w4, #0x1                   	// #1
     4a4:	52800002 	mov	w2, #0x0                   	// #0
     4a8:	2a1703e3 	mov	w3, w23
     4ac:	52800140 	mov	w0, #0xa                   	// #10
     4b0:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     4b4:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     4b8:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     4bc:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     4c0:	39010262 	strb	w2, [x19, #64]
}
     4c4:	f9402bfb 	ldr	x27, [sp, #80]
		emit(A64_CMP(is64, dst, tmp), ctx);
     4c8:	2a1703e4 	mov	w4, w23
     4cc:	12001ea1 	and	w1, w21, #0xff
     4d0:	52800065 	mov	w5, #0x3                   	// #3
     4d4:	52800003 	mov	w3, #0x0                   	// #0
     4d8:	52800142 	mov	w2, #0xa                   	// #10
     4dc:	17ffffbb 	b	3c8 <build_insn+0xc8>
		switch (BPF_OP(code)) {
     4e0:	121c0e94 	and	w20, w20, #0xf0
     4e4:	7100c29f 	cmp	w20, #0x30
     4e8:	54009800 	b.eq	17e8 <build_insn+0x14e8>  // b.none
     4ec:	7102429f 	cmp	w20, #0x90
     4f0:	54fff5e1 	b.ne	3ac <build_insn+0xac>  // b.any
			emit(A64_UDIV(is64, tmp, dst, src), ctx);
     4f4:	12001eb5 	and	w21, w21, #0xff
     4f8:	12001f39 	and	w25, w25, #0xff
     4fc:	2a1903e2 	mov	w2, w25
     500:	2a1503e1 	mov	w1, w21
     504:	2a1703e3 	mov	w3, w23
     508:	52800004 	mov	w4, #0x0                   	// #0
     50c:	52800140 	mov	w0, #0xa                   	// #10
     510:	94000000 	bl	0 <aarch64_insn_gen_data2>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     514:	39410266 	ldrb	w6, [x19, #64]
			emit(A64_UDIV(is64, tmp, dst, src), ctx);
     518:	2a0003e2 	mov	w2, w0
			emit(A64_MSUB(is64, dst, dst, tmp, src), ctx);
     51c:	2a1903e3 	mov	w3, w25
     520:	2a1703e4 	mov	w4, w23
     524:	2a1503e1 	mov	w1, w21
     528:	2a1503e0 	mov	w0, w21
	ctx->bpf2bi_cnt++;
     52c:	110004c7 	add	w7, w6, #0x1
			emit(A64_MSUB(is64, dst, dst, tmp, src), ctx);
     530:	52800025 	mov	w5, #0x1                   	// #1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     534:	b826da62 	str	w2, [x19, w6, sxtw #2]
		pr_err_once("unknown opcode %02x\n", code);
     538:	52800016 	mov	w22, #0x0                   	// #0
			emit(A64_MSUB(is64, dst, dst, tmp, src), ctx);
     53c:	52800142 	mov	w2, #0xa                   	// #10
	ctx->bpf2bi_cnt++;
     540:	39010267 	strb	w7, [x19, #64]
		emit(A64_MSUB(is64, dst, dst, tmp, tmp2), ctx);
     544:	94000000 	bl	0 <aarch64_insn_gen_data3>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     548:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     54c:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     550:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     554:	39010262 	strb	w2, [x19, #64]
}
     558:	17ffff87 	b	374 <build_insn+0x74>
	if (hi & 0x8000) {
     55c:	36f883f8 	tbz	w24, #31, 15d8 <build_insn+0x12d8>
			emit(A64_MOVN(is64, reg, (u16)~lo, 0), ctx);
     560:	2a3803e1 	mvn	w1, w24
     564:	52800044 	mov	w4, #0x2                   	// #2
     568:	12003c21 	and	w1, w1, #0xffff
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
     56c:	52800002 	mov	w2, #0x0                   	// #0
     570:	52800023 	mov	w3, #0x1                   	// #1
     574:	52800160 	mov	w0, #0xb                   	// #11
     578:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     57c:	39410261 	ldrb	w1, [x19, #64]
	u16 hi = val >> 16;
     580:	13107ed7 	asr	w23, w22, #16
     584:	53107ed4 	lsr	w20, w22, #16
	ctx->bpf2bi_cnt++;
     588:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     58c:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     590:	39010262 	strb	w2, [x19, #64]
	if (hi & 0x8000) {
     594:	36f88056 	tbz	w22, #31, 159c <build_insn+0x129c>
	u16 lo = val & 0xffff;
     598:	12003ed8 	and	w24, w22, #0xffff
		if (hi == 0xffff) {
     59c:	529ffff7 	mov	w23, #0xffff                	// #65535
     5a0:	6b17029f 	cmp	w20, w23
     5a4:	5400a680 	b.eq	1a74 <build_insn+0x1774>  // b.none
			emit(A64_MOVN(is64, reg, (u16)~hi, 16), ctx);
     5a8:	2a3403e1 	mvn	w1, w20
     5ac:	52800202 	mov	w2, #0x10                  	// #16
     5b0:	12003c21 	and	w1, w1, #0xffff
     5b4:	52800044 	mov	w4, #0x2                   	// #2
     5b8:	52800023 	mov	w3, #0x1                   	// #1
     5bc:	52800140 	mov	w0, #0xa                   	// #10
     5c0:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     5c4:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     5c8:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     5cc:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     5d0:	39010262 	strb	w2, [x19, #64]
			if (lo != 0xffff)
     5d4:	6b17031f 	cmp	w24, w23
     5d8:	54000160 	b.eq	604 <build_insn+0x304>  // b.none
				emit(A64_MOVK(is64, reg, lo, 0), ctx);
     5dc:	12003ec1 	and	w1, w22, #0xffff
     5e0:	52800024 	mov	w4, #0x1                   	// #1
     5e4:	52800002 	mov	w2, #0x0                   	// #0
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
     5e8:	2a0403e3 	mov	w3, w4
     5ec:	52800140 	mov	w0, #0xa                   	// #10
     5f0:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     5f4:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     5f8:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     5fc:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     600:	39010262 	strb	w2, [x19, #64]
	case BPF_ST | BPF_MEM | BPF_DW:
     604:	7100435f 	cmp	w26, #0x10
     608:	5400a420 	b.eq	1a8c <build_insn+0x178c>  // b.none
     60c:	540065a8 	b.hi	12c0 <build_insn+0xfc0>  // b.pmore
     610:	3400a4da 	cbz	w26, 1aa8 <build_insn+0x17a8>
     614:	7100235f 	cmp	w26, #0x8
     618:	54ffeca1 	b.ne	3ac <build_insn+0xac>  // b.any
		case BPF_W:
     61c:	52800024 	mov	w4, #0x1                   	// #1
     620:	12001ea1 	and	w1, w21, #0xff
     624:	2a0403e3 	mov	w3, w4
     628:	52800162 	mov	w2, #0xb                   	// #11
     62c:	52800140 	mov	w0, #0xa                   	// #10
     630:	94000000 	bl	0 <aarch64_insn_gen_load_store_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     634:	14000019 	b	698 <build_insn+0x398>
	if (hi & 0x8000) {
     638:	36f881d8 	tbz	w24, #31, 1670 <build_insn+0x1370>
			emit(A64_MOVN(is64, reg, (u16)~lo, 0), ctx);
     63c:	2a3803e1 	mvn	w1, w24
     640:	52800044 	mov	w4, #0x2                   	// #2
     644:	12003c21 	and	w1, w1, #0xffff
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
     648:	52800002 	mov	w2, #0x0                   	// #0
     64c:	52800023 	mov	w3, #0x1                   	// #1
     650:	52800140 	mov	w0, #0xa                   	// #10
     654:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     658:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     65c:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     660:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     664:	39010262 	strb	w2, [x19, #64]
	case BPF_STX | BPF_MEM | BPF_H:
     668:	7100435f 	cmp	w26, #0x10
     66c:	54009700 	b.eq	194c <build_insn+0x164c>  // b.none
     670:	540063a8 	b.hi	12e4 <build_insn+0xfe4>  // b.pmore
     674:	34009d1a 	cbz	w26, 1a14 <build_insn+0x1714>
     678:	7100235f 	cmp	w26, #0x8
     67c:	54ffe981 	b.ne	3ac <build_insn+0xac>  // b.any
		case BPF_W:
     680:	52800024 	mov	w4, #0x1                   	// #1
     684:	12001ea1 	and	w1, w21, #0xff
     688:	12001f20 	and	w0, w25, #0xff
     68c:	2a0403e3 	mov	w3, w4
     690:	52800142 	mov	w2, #0xa                   	// #10
     694:	94000000 	bl	0 <aarch64_insn_gen_load_store_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     698:	39410261 	ldrb	w1, [x19, #64]
		pr_err_once("unknown opcode %02x\n", code);
     69c:	52800016 	mov	w22, #0x0                   	// #0
	ctx->bpf2bi_cnt++;
     6a0:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     6a4:	b821da60 	str	w0, [x19, w1, sxtw #2]
		return -EINVAL;
     6a8:	2a1603e0 	mov	w0, w22
	ctx->bpf2bi_cnt++;
     6ac:	39010262 	strb	w2, [x19, #64]
		return -EINVAL;
     6b0:	a94153f3 	ldp	x19, x20, [sp, #16]
     6b4:	a9425bf5 	ldp	x21, x22, [sp, #32]
     6b8:	a94363f7 	ldp	x23, x24, [sp, #48]
     6bc:	a9446bf9 	ldp	x25, x26, [sp, #64]
     6c0:	a8c67bfd 	ldp	x29, x30, [sp], #96
     6c4:	d65f03c0 	ret
	if (hi & 0x8000) {
     6c8:	36f878f8 	tbz	w24, #31, 15e4 <build_insn+0x12e4>
			emit(A64_MOVN(is64, reg, (u16)~lo, 0), ctx);
     6cc:	2a3803e1 	mvn	w1, w24
     6d0:	52800044 	mov	w4, #0x2                   	// #2
     6d4:	12003c21 	and	w1, w1, #0xffff
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
     6d8:	52800002 	mov	w2, #0x0                   	// #0
     6dc:	52800023 	mov	w3, #0x1                   	// #1
     6e0:	52800140 	mov	w0, #0xa                   	// #10
     6e4:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     6e8:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     6ec:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     6f0:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     6f4:	39010262 	strb	w2, [x19, #64]
	case BPF_LDX | BPF_MEM | BPF_H:
     6f8:	7100435f 	cmp	w26, #0x10
     6fc:	540097e0 	b.eq	19f8 <build_insn+0x16f8>  // b.none
     700:	54006048 	b.hi	1308 <build_insn+0x1008>  // b.pmore
     704:	3400997a 	cbz	w26, 1a30 <build_insn+0x1730>
     708:	7100235f 	cmp	w26, #0x8
     70c:	54ffe501 	b.ne	3ac <build_insn+0xac>  // b.any
		case BPF_W:
     710:	12001f21 	and	w1, w25, #0xff
     714:	12001ea0 	and	w0, w21, #0xff
     718:	52800004 	mov	w4, #0x0                   	// #0
     71c:	52800023 	mov	w3, #0x1                   	// #1
     720:	52800142 	mov	w2, #0xa                   	// #10
     724:	94000000 	bl	0 <aarch64_insn_gen_load_store_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     728:	17ffffdc 	b	698 <build_insn+0x398>
		emit(A64_LSLV(is64, dst, dst, src), ctx);
     72c:	12001ea1 	and	w1, w21, #0xff
     730:	2a1703e3 	mov	w3, w23
     734:	12001f22 	and	w2, w25, #0xff
     738:	2a0103e0 	mov	w0, w1
     73c:	52800044 	mov	w4, #0x2                   	// #2
     740:	94000000 	bl	0 <aarch64_insn_gen_data2>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     744:	17ffffd5 	b	698 <build_insn+0x398>
	u16 hi = val >> 16;
     748:	13107ed8 	asr	w24, w22, #16
     74c:	53107ed4 	lsr	w20, w22, #16
	if (hi & 0x8000) {
     750:	36f87c36 	tbz	w22, #31, 16d4 <build_insn+0x13d4>
	u16 lo = val & 0xffff;
     754:	12003ed9 	and	w25, w22, #0xffff
		if (hi == 0xffff) {
     758:	529ffff8 	mov	w24, #0xffff                	// #65535
     75c:	6b18029f 	cmp	w20, w24
     760:	54008ca0 	b.eq	18f4 <build_insn+0x15f4>  // b.none
			emit(A64_MOVN(is64, reg, (u16)~hi, 16), ctx);
     764:	2a3403e1 	mvn	w1, w20
     768:	52800202 	mov	w2, #0x10                  	// #16
     76c:	12003c21 	and	w1, w1, #0xffff
     770:	2a1703e3 	mov	w3, w23
     774:	52800044 	mov	w4, #0x2                   	// #2
     778:	52800140 	mov	w0, #0xa                   	// #10
     77c:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     780:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     784:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     788:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     78c:	39010262 	strb	w2, [x19, #64]
			if (lo != 0xffff)
     790:	6b18033f 	cmp	w25, w24
     794:	54000160 	b.eq	7c0 <build_insn+0x4c0>  // b.none
				emit(A64_MOVK(is64, reg, lo, 0), ctx);
     798:	12003ec1 	and	w1, w22, #0xffff
     79c:	2a1703e3 	mov	w3, w23
     7a0:	52800024 	mov	w4, #0x1                   	// #1
     7a4:	52800002 	mov	w2, #0x0                   	// #0
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
     7a8:	52800140 	mov	w0, #0xa                   	// #10
     7ac:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     7b0:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     7b4:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     7b8:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     7bc:	39010262 	strb	w2, [x19, #64]
		emit(A64_UDIV(is64, dst, dst, tmp), ctx);
     7c0:	12001ea1 	and	w1, w21, #0xff
     7c4:	2a1703e3 	mov	w3, w23
     7c8:	2a0103e0 	mov	w0, w1
     7cc:	52800004 	mov	w4, #0x0                   	// #0
     7d0:	52800142 	mov	w2, #0xa                   	// #10
     7d4:	94000000 	bl	0 <aarch64_insn_gen_data2>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     7d8:	17ffffb0 	b	698 <build_insn+0x398>
		emit(A64_MOV(is64, dst, src), ctx);
     7dc:	2a1703e3 	mov	w3, w23
     7e0:	12001f21 	and	w1, w25, #0xff
     7e4:	12001ea0 	and	w0, w21, #0xff
     7e8:	52800004 	mov	w4, #0x0                   	// #0
     7ec:	52800002 	mov	w2, #0x0                   	// #0
     7f0:	94000000 	bl	0 <aarch64_insn_gen_add_sub_imm>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     7f4:	17ffffa9 	b	698 <build_insn+0x398>
	u16 hi = val >> 16;
     7f8:	13107ed8 	asr	w24, w22, #16
     7fc:	53107ed4 	lsr	w20, w22, #16
	if (hi & 0x8000) {
     800:	36f87196 	tbz	w22, #31, 1630 <build_insn+0x1330>
	u16 lo = val & 0xffff;
     804:	12003ed9 	and	w25, w22, #0xffff
		if (hi == 0xffff) {
     808:	529ffff8 	mov	w24, #0xffff                	// #65535
     80c:	6b18029f 	cmp	w20, w24
     810:	54008920 	b.eq	1934 <build_insn+0x1634>  // b.none
			emit(A64_MOVN(is64, reg, (u16)~hi, 16), ctx);
     814:	2a3403e1 	mvn	w1, w20
     818:	52800202 	mov	w2, #0x10                  	// #16
     81c:	12003c21 	and	w1, w1, #0xffff
     820:	2a1703e3 	mov	w3, w23
     824:	52800044 	mov	w4, #0x2                   	// #2
     828:	52800160 	mov	w0, #0xb                   	// #11
     82c:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     830:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     834:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     838:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     83c:	39010262 	strb	w2, [x19, #64]
			if (lo != 0xffff)
     840:	6b18033f 	cmp	w25, w24
     844:	54000160 	b.eq	870 <build_insn+0x570>  // b.none
				emit(A64_MOVK(is64, reg, lo, 0), ctx);
     848:	12003ec1 	and	w1, w22, #0xffff
     84c:	2a1703e3 	mov	w3, w23
     850:	52800024 	mov	w4, #0x1                   	// #1
     854:	52800002 	mov	w2, #0x0                   	// #0
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
     858:	52800160 	mov	w0, #0xb                   	// #11
     85c:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     860:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     864:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     868:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     86c:	39010262 	strb	w2, [x19, #64]
		emit(A64_UDIV(is64, tmp, dst, tmp2), ctx);
     870:	12001eb5 	and	w21, w21, #0xff
     874:	2a1703e3 	mov	w3, w23
     878:	2a1503e1 	mov	w1, w21
     87c:	52800004 	mov	w4, #0x0                   	// #0
     880:	52800162 	mov	w2, #0xb                   	// #11
     884:	52800140 	mov	w0, #0xa                   	// #10
     888:	94000000 	bl	0 <aarch64_insn_gen_data2>
     88c:	2a0003e8 	mov	w8, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     890:	39410266 	ldrb	w6, [x19, #64]
		emit(A64_MSUB(is64, dst, dst, tmp, tmp2), ctx);
     894:	2a1703e4 	mov	w4, w23
     898:	2a1503e1 	mov	w1, w21
     89c:	2a1503e0 	mov	w0, w21
	ctx->bpf2bi_cnt++;
     8a0:	110004c7 	add	w7, w6, #0x1
		emit(A64_MSUB(is64, dst, dst, tmp, tmp2), ctx);
     8a4:	52800025 	mov	w5, #0x1                   	// #1
     8a8:	52800163 	mov	w3, #0xb                   	// #11
     8ac:	52800142 	mov	w2, #0xa                   	// #10
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     8b0:	b826da68 	str	w8, [x19, w6, sxtw #2]
		pr_err_once("unknown opcode %02x\n", code);
     8b4:	52800016 	mov	w22, #0x0                   	// #0
	ctx->bpf2bi_cnt++;
     8b8:	39010267 	strb	w7, [x19, #64]
     8bc:	17ffff22 	b	544 <build_insn+0x244>
		emit(A64_NEG(is64, dst, dst), ctx);
     8c0:	12001ea2 	and	w2, w21, #0xff
     8c4:	2a1703e4 	mov	w4, w23
     8c8:	2a0203e0 	mov	w0, w2
     8cc:	52800025 	mov	w5, #0x1                   	// #1
     8d0:	52800003 	mov	w3, #0x0                   	// #0
     8d4:	528003e1 	mov	w1, #0x1f                  	// #31
		emit(A64_ADD(is64, dst, dst, src), ctx);
     8d8:	94000000 	bl	0 <aarch64_insn_gen_add_sub_shifted_reg>
     8dc:	17ffff6f 	b	698 <build_insn+0x398>
		emit(A64_LSRV(is64, dst, dst, src), ctx);
     8e0:	12001ea1 	and	w1, w21, #0xff
     8e4:	2a1703e3 	mov	w3, w23
     8e8:	12001f22 	and	w2, w25, #0xff
     8ec:	2a0103e0 	mov	w0, w1
     8f0:	52800064 	mov	w4, #0x3                   	// #3
     8f4:	94000000 	bl	0 <aarch64_insn_gen_data2>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     8f8:	17ffff68 	b	698 <build_insn+0x398>
		emit(A64_AND(is64, dst, dst, src), ctx);
     8fc:	12001ea1 	and	w1, w21, #0xff
     900:	2a1703e4 	mov	w4, w23
     904:	12001f22 	and	w2, w25, #0xff
     908:	2a0103e0 	mov	w0, w1
     90c:	52800005 	mov	w5, #0x0                   	// #0
     910:	52800003 	mov	w3, #0x0                   	// #0
     914:	94000000 	bl	0 <aarch64_insn_gen_logical_shifted_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     918:	17ffff60 	b	698 <build_insn+0x398>
	u16 hi = val >> 16;
     91c:	13107ed8 	asr	w24, w22, #16
     920:	53107ed4 	lsr	w20, w22, #16
	if (hi & 0x8000) {
     924:	36f86676 	tbz	w22, #31, 15f0 <build_insn+0x12f0>
	u16 lo = val & 0xffff;
     928:	12003ed9 	and	w25, w22, #0xffff
		if (hi == 0xffff) {
     92c:	529ffff8 	mov	w24, #0xffff                	// #65535
     930:	6b18029f 	cmp	w20, w24
     934:	54007f40 	b.eq	191c <build_insn+0x161c>  // b.none
			emit(A64_MOVN(is64, reg, (u16)~hi, 16), ctx);
     938:	2a3403e1 	mvn	w1, w20
     93c:	52800202 	mov	w2, #0x10                  	// #16
     940:	12003c21 	and	w1, w1, #0xffff
     944:	2a1703e3 	mov	w3, w23
     948:	52800044 	mov	w4, #0x2                   	// #2
     94c:	52800140 	mov	w0, #0xa                   	// #10
     950:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     954:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     958:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     95c:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     960:	39010262 	strb	w2, [x19, #64]
			if (lo != 0xffff)
     964:	6b18033f 	cmp	w25, w24
     968:	54000160 	b.eq	994 <build_insn+0x694>  // b.none
				emit(A64_MOVK(is64, reg, lo, 0), ctx);
     96c:	12003ec1 	and	w1, w22, #0xffff
     970:	2a1703e3 	mov	w3, w23
     974:	52800024 	mov	w4, #0x1                   	// #1
     978:	52800002 	mov	w2, #0x0                   	// #0
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
     97c:	52800140 	mov	w0, #0xa                   	// #10
     980:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     984:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     988:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     98c:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     990:	39010262 	strb	w2, [x19, #64]
		emit(A64_AND(is64, dst, dst, tmp), ctx);
     994:	12001ea1 	and	w1, w21, #0xff
     998:	2a1703e4 	mov	w4, w23
     99c:	2a0103e0 	mov	w0, w1
     9a0:	52800005 	mov	w5, #0x0                   	// #0
     9a4:	52800003 	mov	w3, #0x0                   	// #0
     9a8:	52800142 	mov	w2, #0xa                   	// #10
     9ac:	94000000 	bl	0 <aarch64_insn_gen_logical_shifted_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     9b0:	17ffff3a 	b	698 <build_insn+0x398>
		emit(A64_MUL(is64, dst, dst, src), ctx);
     9b4:	12001ea2 	and	w2, w21, #0xff
     9b8:	2a1703e4 	mov	w4, w23
     9bc:	12001f23 	and	w3, w25, #0xff
     9c0:	2a0203e0 	mov	w0, w2
     9c4:	52800005 	mov	w5, #0x0                   	// #0
     9c8:	528003e1 	mov	w1, #0x1f                  	// #31
     9cc:	94000000 	bl	0 <aarch64_insn_gen_data3>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     9d0:	17ffff32 	b	698 <build_insn+0x398>
	u16 hi = val >> 16;
     9d4:	13107ed8 	asr	w24, w22, #16
     9d8:	53107ed4 	lsr	w20, w22, #16
	if (hi & 0x8000) {
     9dc:	36f85c16 	tbz	w22, #31, 155c <build_insn+0x125c>
	u16 lo = val & 0xffff;
     9e0:	12003ed9 	and	w25, w22, #0xffff
		if (hi == 0xffff) {
     9e4:	529ffff8 	mov	w24, #0xffff                	// #65535
     9e8:	6b18029f 	cmp	w20, w24
     9ec:	54007fa0 	b.eq	19e0 <build_insn+0x16e0>  // b.none
			emit(A64_MOVN(is64, reg, (u16)~hi, 16), ctx);
     9f0:	2a3403e1 	mvn	w1, w20
     9f4:	52800202 	mov	w2, #0x10                  	// #16
     9f8:	12003c21 	and	w1, w1, #0xffff
     9fc:	2a1703e3 	mov	w3, w23
     a00:	52800044 	mov	w4, #0x2                   	// #2
     a04:	52800140 	mov	w0, #0xa                   	// #10
     a08:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     a0c:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     a10:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     a14:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     a18:	39010262 	strb	w2, [x19, #64]
			if (lo != 0xffff)
     a1c:	6b18033f 	cmp	w25, w24
     a20:	54000160 	b.eq	a4c <build_insn+0x74c>  // b.none
				emit(A64_MOVK(is64, reg, lo, 0), ctx);
     a24:	12003ec1 	and	w1, w22, #0xffff
     a28:	2a1703e3 	mov	w3, w23
     a2c:	52800024 	mov	w4, #0x1                   	// #1
     a30:	52800002 	mov	w2, #0x0                   	// #0
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
     a34:	52800140 	mov	w0, #0xa                   	// #10
     a38:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     a3c:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     a40:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     a44:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     a48:	39010262 	strb	w2, [x19, #64]
		emit(A64_MUL(is64, dst, dst, tmp), ctx);
     a4c:	12001ea2 	and	w2, w21, #0xff
     a50:	2a1703e4 	mov	w4, w23
     a54:	2a0203e0 	mov	w0, w2
     a58:	52800005 	mov	w5, #0x0                   	// #0
     a5c:	52800143 	mov	w3, #0xa                   	// #10
     a60:	528003e1 	mov	w1, #0x1f                  	// #31
     a64:	94000000 	bl	0 <aarch64_insn_gen_data3>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     a68:	17ffff0c 	b	698 <build_insn+0x398>
		emit(A64_TST(is64, dst, src), ctx);
     a6c:	2a1703e4 	mov	w4, w23
     a70:	12001f22 	and	w2, w25, #0xff
     a74:	12001ea1 	and	w1, w21, #0xff
     a78:	528000c5 	mov	w5, #0x6                   	// #6
     a7c:	52800003 	mov	w3, #0x0                   	// #0
		emit(A64_TST(is64, dst, tmp), ctx);
     a80:	528003e0 	mov	w0, #0x1f                  	// #31
     a84:	94000000 	bl	0 <aarch64_insn_gen_logical_shifted_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     a88:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     a8c:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     a90:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     a94:	39010262 	strb	w2, [x19, #64]
		goto emit_cond_jmp;
     a98:	17fffe52 	b	3e0 <build_insn+0xe0>
		emit(A64_ORR(is64, dst, dst, src), ctx);
     a9c:	12001ea1 	and	w1, w21, #0xff
     aa0:	2a1703e4 	mov	w4, w23
     aa4:	12001f22 	and	w2, w25, #0xff
     aa8:	2a0103e0 	mov	w0, w1
     aac:	52800045 	mov	w5, #0x2                   	// #2
     ab0:	52800003 	mov	w3, #0x0                   	// #0
     ab4:	94000000 	bl	0 <aarch64_insn_gen_logical_shifted_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     ab8:	17fffef8 	b	698 <build_insn+0x398>
	u16 hi = val >> 16;
     abc:	13107eda 	asr	w26, w22, #16
     ac0:	53107ed9 	lsr	w25, w22, #16
	if (hi & 0x8000) {
     ac4:	36f85dd6 	tbz	w22, #31, 167c <build_insn+0x137c>
     ac8:	f9002bfb 	str	x27, [sp, #80]
		if (hi == 0xffff) {
     acc:	529ffffa 	mov	w26, #0xffff                	// #65535
	u16 lo = val & 0xffff;
     ad0:	12003edb 	and	w27, w22, #0xffff
		if (hi == 0xffff) {
     ad4:	6b1a033f 	cmp	w25, w26
     ad8:	54007480 	b.eq	1968 <build_insn+0x1668>  // b.none
			emit(A64_MOVN(is64, reg, (u16)~hi, 16), ctx);
     adc:	2a3903e1 	mvn	w1, w25
     ae0:	52800202 	mov	w2, #0x10                  	// #16
     ae4:	12003c21 	and	w1, w1, #0xffff
     ae8:	2a1703e3 	mov	w3, w23
     aec:	52800044 	mov	w4, #0x2                   	// #2
     af0:	52800140 	mov	w0, #0xa                   	// #10
     af4:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     af8:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     afc:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     b00:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     b04:	39010262 	strb	w2, [x19, #64]
			if (lo != 0xffff)
     b08:	6b1a037f 	cmp	w27, w26
     b0c:	54006f00 	b.eq	18ec <build_insn+0x15ec>  // b.none
				emit(A64_MOVK(is64, reg, lo, 0), ctx);
     b10:	12003ec1 	and	w1, w22, #0xffff
     b14:	52800024 	mov	w4, #0x1                   	// #1
     b18:	52800002 	mov	w2, #0x0                   	// #0
     b1c:	2a1703e3 	mov	w3, w23
     b20:	52800140 	mov	w0, #0xa                   	// #10
     b24:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     b28:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     b2c:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     b30:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     b34:	39010262 	strb	w2, [x19, #64]
}
     b38:	f9402bfb 	ldr	x27, [sp, #80]
		emit(A64_TST(is64, dst, tmp), ctx);
     b3c:	2a1703e4 	mov	w4, w23
     b40:	12001ea1 	and	w1, w21, #0xff
     b44:	528000c5 	mov	w5, #0x6                   	// #6
     b48:	52800003 	mov	w3, #0x0                   	// #0
     b4c:	52800142 	mov	w2, #0xa                   	// #10
     b50:	17ffffcc 	b	a80 <build_insn+0x780>
	u16 hi = val >> 16;
     b54:	13107ed5 	asr	w21, w22, #16
     b58:	53107ed4 	lsr	w20, w22, #16
	if (hi & 0x8000) {
     b5c:	36f84bd6 	tbz	w22, #31, 14d4 <build_insn+0x11d4>
	u16 lo = val & 0xffff;
     b60:	12003ed8 	and	w24, w22, #0xffff
		if (hi == 0xffff) {
     b64:	529ffff5 	mov	w21, #0xffff                	// #65535
     b68:	6b15029f 	cmp	w20, w21
     b6c:	54007700 	b.eq	1a4c <build_insn+0x174c>  // b.none
			emit(A64_MOVN(is64, reg, (u16)~hi, 16), ctx);
     b70:	2a3403e1 	mvn	w1, w20
     b74:	52800202 	mov	w2, #0x10                  	// #16
     b78:	12003c21 	and	w1, w1, #0xffff
     b7c:	2a1703e3 	mov	w3, w23
     b80:	52800044 	mov	w4, #0x2                   	// #2
     b84:	52800140 	mov	w0, #0xa                   	// #10
     b88:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     b8c:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     b90:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     b94:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     b98:	39010262 	strb	w2, [x19, #64]
			if (lo != 0xffff)
     b9c:	6b15031f 	cmp	w24, w21
     ba0:	54ffc060 	b.eq	3ac <build_insn+0xac>  // b.none
				emit(A64_MOVK(is64, reg, lo, 0), ctx);
     ba4:	2a1703e3 	mov	w3, w23
     ba8:	12003ec1 	and	w1, w22, #0xffff
     bac:	52800024 	mov	w4, #0x1                   	// #1
     bb0:	52800002 	mov	w2, #0x0                   	// #0
     bb4:	52800140 	mov	w0, #0xa                   	// #10
     bb8:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     bbc:	17fffeb7 	b	698 <build_insn+0x398>
		emit(A64_ASR(is64, dst, dst, imm), ctx);
     bc0:	7100143f 	cmp	w1, #0x5
     bc4:	528003e0 	mov	w0, #0x1f                  	// #31
     bc8:	12001ea1 	and	w1, w21, #0xff
     bcc:	2a1703e4 	mov	w4, w23
     bd0:	2a1603e2 	mov	w2, w22
     bd4:	528007e3 	mov	w3, #0x3f                  	// #63
     bd8:	52800045 	mov	w5, #0x2                   	// #2
     bdc:	1a800063 	csel	w3, w3, w0, eq  // eq = none
     be0:	2a0103e0 	mov	w0, w1
     be4:	94000000 	bl	0 <aarch64_insn_gen_bitfield>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     be8:	17fffeac 	b	698 <build_insn+0x398>
	/* STX XADD: lock *(u32 *)(dst + off) += src */
     bec:	350060d8 	cbnz	w24, 1804 <build_insn+0x1504>
			emit(A64_ADD(1, tmp, tmp, dst), ctx);
     bf0:	12001eb5 	and	w21, w21, #0xff
 * @nr: bit number to test
 * @addr: Address to start counting from
 */
static inline int test_bit(int nr, const volatile unsigned long *addr)
{
	return 1UL & (addr[BIT_WORD(nr)] >> (nr & (BITS_PER_LONG-1)));
     bf4:	90000000 	adrp	x0, 0 <cpu_hwcaps>
		emit(A64_MOV(is64, dst, src), ctx);
     bf8:	12001f39 	and	w25, w25, #0xff
     bfc:	f9400000 	ldr	x0, [x0]
			emit_a64_mov_i(1, tmp, off, ctx);
     c00:	721b001f 	tst	w0, #0x20
     c04:	540039c0 	b.eq	133c <build_insn+0x103c>  // b.none
			emit(A64_ADD(1, tmp, tmp, dst), ctx);
     c08:	7100635f 	cmp	w26, #0x18
     c0c:	2a1903e1 	mov	w1, w25
     c10:	1a9f17e2 	cset	w2, eq  // eq = none
     c14:	2a1503e0 	mov	w0, w21
     c18:	11000842 	add	w2, w2, #0x2
		pr_err_once("unknown opcode %02x\n", code);
     c1c:	52800016 	mov	w22, #0x0                   	// #0
			emit(A64_ADD(1, tmp, tmp, dst), ctx);
     c20:	94000000 	bl	0 <aarch64_insn_gen_stadd>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     c24:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     c28:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     c2c:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     c30:	39010262 	strb	w2, [x19, #64]
}
     c34:	17fffdd0 	b	374 <build_insn+0x74>
		emit(A64_ADD(is64, dst, dst, src), ctx);
     c38:	12001ea1 	and	w1, w21, #0xff
     c3c:	2a1703e4 	mov	w4, w23
     c40:	12001f22 	and	w2, w25, #0xff
     c44:	2a0103e0 	mov	w0, w1
     c48:	52800005 	mov	w5, #0x0                   	// #0
     c4c:	52800003 	mov	w3, #0x0                   	// #0
     c50:	94000000 	bl	0 <aarch64_insn_gen_add_sub_shifted_reg>
     c54:	17fffe91 	b	698 <build_insn+0x398>
	u16 hi = val >> 16;
     c58:	13107ed8 	asr	w24, w22, #16
     c5c:	53107ed4 	lsr	w20, w22, #16
	if (hi & 0x8000) {
     c60:	36f845f6 	tbz	w22, #31, 151c <build_insn+0x121c>
	u16 lo = val & 0xffff;
     c64:	12003ed9 	and	w25, w22, #0xffff
		if (hi == 0xffff) {
     c68:	529ffff8 	mov	w24, #0xffff                	// #65535
     c6c:	6b18029f 	cmp	w20, w24
     c70:	54006900 	b.eq	1990 <build_insn+0x1690>  // b.none
			emit(A64_MOVN(is64, reg, (u16)~hi, 16), ctx);
     c74:	2a3403e1 	mvn	w1, w20
     c78:	52800202 	mov	w2, #0x10                  	// #16
     c7c:	12003c21 	and	w1, w1, #0xffff
     c80:	2a1703e3 	mov	w3, w23
     c84:	52800044 	mov	w4, #0x2                   	// #2
     c88:	52800140 	mov	w0, #0xa                   	// #10
     c8c:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     c90:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     c94:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     c98:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     c9c:	39010262 	strb	w2, [x19, #64]
			if (lo != 0xffff)
     ca0:	6b18033f 	cmp	w25, w24
     ca4:	54000160 	b.eq	cd0 <build_insn+0x9d0>  // b.none
				emit(A64_MOVK(is64, reg, lo, 0), ctx);
     ca8:	12003ec1 	and	w1, w22, #0xffff
     cac:	2a1703e3 	mov	w3, w23
     cb0:	52800024 	mov	w4, #0x1                   	// #1
     cb4:	52800002 	mov	w2, #0x0                   	// #0
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
     cb8:	52800140 	mov	w0, #0xa                   	// #10
     cbc:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     cc0:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     cc4:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     cc8:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     ccc:	39010262 	strb	w2, [x19, #64]
		emit(A64_SUB(is64, dst, dst, tmp), ctx);
     cd0:	12001ea1 	and	w1, w21, #0xff
     cd4:	2a1703e4 	mov	w4, w23
     cd8:	2a0103e0 	mov	w0, w1
     cdc:	52800025 	mov	w5, #0x1                   	// #1
     ce0:	52800003 	mov	w3, #0x0                   	// #0
     ce4:	52800142 	mov	w2, #0xa                   	// #10
		emit(A64_ADD(is64, dst, dst, src), ctx);
     ce8:	94000000 	bl	0 <aarch64_insn_gen_add_sub_shifted_reg>
     cec:	17fffe6b 	b	698 <build_insn+0x398>
		emit(A64_ASRV(is64, dst, dst, src), ctx);
     cf0:	12001ea1 	and	w1, w21, #0xff
     cf4:	2a1703e3 	mov	w3, w23
     cf8:	12001f22 	and	w2, w25, #0xff
     cfc:	2a0103e0 	mov	w0, w1
     d00:	52800084 	mov	w4, #0x4                   	// #4
     d04:	94000000 	bl	0 <aarch64_insn_gen_data2>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     d08:	17fffe64 	b	698 <build_insn+0x398>
		emit(A64_MOV(is64, dst, src), ctx);
     d0c:	12001eb5 	and	w21, w21, #0xff
	u16 hi = val >> 16;
     d10:	13107ed8 	asr	w24, w22, #16
     d14:	53107ed4 	lsr	w20, w22, #16
	if (hi & 0x8000) {
     d18:	36f839b6 	tbz	w22, #31, 144c <build_insn+0x114c>
	u16 lo = val & 0xffff;
     d1c:	12003ed9 	and	w25, w22, #0xffff
		if (hi == 0xffff) {
     d20:	529ffff8 	mov	w24, #0xffff                	// #65535
     d24:	6b18029f 	cmp	w20, w24
     d28:	54006400 	b.eq	19a8 <build_insn+0x16a8>  // b.none
			emit(A64_MOVN(is64, reg, (u16)~hi, 16), ctx);
     d2c:	2a3403e1 	mvn	w1, w20
     d30:	52800202 	mov	w2, #0x10                  	// #16
     d34:	12003c21 	and	w1, w1, #0xffff
     d38:	2a1703e3 	mov	w3, w23
     d3c:	2a1503e0 	mov	w0, w21
     d40:	52800044 	mov	w4, #0x2                   	// #2
     d44:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     d48:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     d4c:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     d50:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     d54:	39010262 	strb	w2, [x19, #64]
			if (lo != 0xffff)
     d58:	6b18033f 	cmp	w25, w24
     d5c:	54ffb280 	b.eq	3ac <build_insn+0xac>  // b.none
				emit(A64_MOVK(is64, reg, lo, 0), ctx);
     d60:	2a1703e3 	mov	w3, w23
     d64:	12003ec1 	and	w1, w22, #0xffff
     d68:	2a1503e0 	mov	w0, w21
     d6c:	52800024 	mov	w4, #0x1                   	// #1
     d70:	52800002 	mov	w2, #0x0                   	// #0
     d74:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     d78:	17fffe48 	b	698 <build_insn+0x398>
		emit(A64_EOR(is64, dst, dst, src), ctx);
     d7c:	12001ea1 	and	w1, w21, #0xff
     d80:	2a1703e4 	mov	w4, w23
     d84:	12001f22 	and	w2, w25, #0xff
     d88:	2a0103e0 	mov	w0, w1
     d8c:	52800085 	mov	w5, #0x4                   	// #4
     d90:	52800003 	mov	w3, #0x0                   	// #0
     d94:	94000000 	bl	0 <aarch64_insn_gen_logical_shifted_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     d98:	17fffe40 	b	698 <build_insn+0x398>
	u16 hi = val >> 16;
     d9c:	13107ed8 	asr	w24, w22, #16
     da0:	53107ed4 	lsr	w20, w22, #16
	if (hi & 0x8000) {
     da4:	36f83356 	tbz	w22, #31, 140c <build_insn+0x110c>
	u16 lo = val & 0xffff;
     da8:	12003ed9 	and	w25, w22, #0xffff
		if (hi == 0xffff) {
     dac:	529ffff8 	mov	w24, #0xffff                	// #65535
     db0:	6b18029f 	cmp	w20, w24
     db4:	54005e20 	b.eq	1978 <build_insn+0x1678>  // b.none
			emit(A64_MOVN(is64, reg, (u16)~hi, 16), ctx);
     db8:	2a3403e1 	mvn	w1, w20
     dbc:	52800202 	mov	w2, #0x10                  	// #16
     dc0:	12003c21 	and	w1, w1, #0xffff
     dc4:	2a1703e3 	mov	w3, w23
     dc8:	52800044 	mov	w4, #0x2                   	// #2
     dcc:	52800140 	mov	w0, #0xa                   	// #10
     dd0:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     dd4:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     dd8:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     ddc:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     de0:	39010262 	strb	w2, [x19, #64]
			if (lo != 0xffff)
     de4:	6b18033f 	cmp	w25, w24
     de8:	54000160 	b.eq	e14 <build_insn+0xb14>  // b.none
				emit(A64_MOVK(is64, reg, lo, 0), ctx);
     dec:	12003ec1 	and	w1, w22, #0xffff
     df0:	2a1703e3 	mov	w3, w23
     df4:	52800024 	mov	w4, #0x1                   	// #1
     df8:	52800002 	mov	w2, #0x0                   	// #0
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
     dfc:	52800140 	mov	w0, #0xa                   	// #10
     e00:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     e04:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     e08:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     e0c:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     e10:	39010262 	strb	w2, [x19, #64]
		emit(A64_EOR(is64, dst, dst, tmp), ctx);
     e14:	12001ea1 	and	w1, w21, #0xff
     e18:	2a1703e4 	mov	w4, w23
     e1c:	2a0103e0 	mov	w0, w1
     e20:	52800085 	mov	w5, #0x4                   	// #4
     e24:	52800003 	mov	w3, #0x0                   	// #0
     e28:	52800142 	mov	w2, #0xa                   	// #10
     e2c:	94000000 	bl	0 <aarch64_insn_gen_logical_shifted_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     e30:	17fffe1a 	b	698 <build_insn+0x398>
	u16 hi = val >> 16;
     e34:	13107ed8 	asr	w24, w22, #16
     e38:	53107ed4 	lsr	w20, w22, #16
	if (hi & 0x8000) {
     e3c:	36f832d6 	tbz	w22, #31, 1494 <build_insn+0x1194>
	u16 lo = val & 0xffff;
     e40:	12003ed9 	and	w25, w22, #0xffff
		if (hi == 0xffff) {
     e44:	529ffff8 	mov	w24, #0xffff                	// #65535
     e48:	6b18029f 	cmp	w20, w24
     e4c:	54005be0 	b.eq	19c8 <build_insn+0x16c8>  // b.none
			emit(A64_MOVN(is64, reg, (u16)~hi, 16), ctx);
     e50:	2a3403e1 	mvn	w1, w20
     e54:	52800202 	mov	w2, #0x10                  	// #16
     e58:	12003c21 	and	w1, w1, #0xffff
     e5c:	2a1703e3 	mov	w3, w23
     e60:	52800044 	mov	w4, #0x2                   	// #2
     e64:	52800140 	mov	w0, #0xa                   	// #10
     e68:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     e6c:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     e70:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     e74:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     e78:	39010262 	strb	w2, [x19, #64]
			if (lo != 0xffff)
     e7c:	6b18033f 	cmp	w25, w24
     e80:	54000160 	b.eq	eac <build_insn+0xbac>  // b.none
				emit(A64_MOVK(is64, reg, lo, 0), ctx);
     e84:	12003ec1 	and	w1, w22, #0xffff
     e88:	2a1703e3 	mov	w3, w23
     e8c:	52800024 	mov	w4, #0x1                   	// #1
     e90:	52800002 	mov	w2, #0x0                   	// #0
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
     e94:	52800140 	mov	w0, #0xa                   	// #10
     e98:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     e9c:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     ea0:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     ea4:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     ea8:	39010262 	strb	w2, [x19, #64]
		emit(A64_ADD(is64, dst, dst, tmp), ctx);
     eac:	12001ea1 	and	w1, w21, #0xff
     eb0:	2a1703e4 	mov	w4, w23
     eb4:	2a0103e0 	mov	w0, w1
     eb8:	52800005 	mov	w5, #0x0                   	// #0
     ebc:	52800003 	mov	w3, #0x0                   	// #0
     ec0:	52800142 	mov	w2, #0xa                   	// #10
		emit(A64_ADD(is64, dst, dst, src), ctx);
     ec4:	94000000 	bl	0 <aarch64_insn_gen_add_sub_shifted_reg>
     ec8:	17fffdf4 	b	698 <build_insn+0x398>
		if (BPF_SRC(code) == BPF_FROM_LE)
     ecc:	36184774 	tbz	w20, #3, 17b8 <build_insn+0x14b8>
		switch (imm) {
     ed0:	710082df 	cmp	w22, #0x20
     ed4:	54006040 	b.eq	1adc <build_insn+0x17dc>  // b.none
     ed8:	710102df 	cmp	w22, #0x40
     edc:	54005f40 	b.eq	1ac4 <build_insn+0x17c4>  // b.none
     ee0:	710042df 	cmp	w22, #0x10
     ee4:	54ffa641 	b.ne	3ac <build_insn+0xac>  // b.any
			emit(A64_REV16(is64, dst, dst), ctx);
     ee8:	12001eb5 	and	w21, w21, #0xff
     eec:	2a1703e2 	mov	w2, w23
     ef0:	2a1503e1 	mov	w1, w21
     ef4:	52800003 	mov	w3, #0x0                   	// #0
     ef8:	2a1503e0 	mov	w0, w21
     efc:	94000000 	bl	0 <aarch64_insn_gen_data1>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     f00:	39410262 	ldrb	w2, [x19, #64]
			emit(A64_REV16(is64, dst, dst), ctx);
     f04:	2a0003e7 	mov	w7, w0
			emit(A64_UXTH(is64, dst, dst), ctx);
     f08:	2a1703e4 	mov	w4, w23
     f0c:	2a1503e1 	mov	w1, w21
     f10:	2a1503e0 	mov	w0, w21
	ctx->bpf2bi_cnt++;
     f14:	11000446 	add	w6, w2, #0x1
			emit(A64_UXTH(is64, dst, dst), ctx);
     f18:	52800025 	mov	w5, #0x1                   	// #1
     f1c:	528001e3 	mov	w3, #0xf                   	// #15
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     f20:	b822da67 	str	w7, [x19, w2, sxtw #2]
		pr_err_once("unknown opcode %02x\n", code);
     f24:	52800016 	mov	w22, #0x0                   	// #0
			emit(A64_UXTH(is64, dst, dst), ctx);
     f28:	52800002 	mov	w2, #0x0                   	// #0
	ctx->bpf2bi_cnt++;
     f2c:	39010266 	strb	w6, [x19, #64]
		emit(A64_LSL(is64, dst, dst, imm), ctx);
     f30:	94000000 	bl	0 <aarch64_insn_gen_bitfield>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     f34:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
     f38:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     f3c:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
     f40:	39010262 	strb	w2, [x19, #64]
}
     f44:	17fffd0c 	b	374 <build_insn+0x74>
		emit(A64_SUB(is64, dst, dst, src), ctx);
     f48:	12001ea1 	and	w1, w21, #0xff
     f4c:	2a1703e4 	mov	w4, w23
     f50:	12001f22 	and	w2, w25, #0xff
     f54:	2a0103e0 	mov	w0, w1
     f58:	52800025 	mov	w5, #0x1                   	// #1
		emit(A64_ADD(is64, dst, dst, src), ctx);
     f5c:	52800003 	mov	w3, #0x0                   	// #0
     f60:	17ffff3c 	b	c50 <build_insn+0x950>
		emit(A64_LSL(is64, dst, dst, imm), ctx);
     f64:	7100143f 	cmp	w1, #0x5
     f68:	540024c0 	b.eq	1400 <build_insn+0x1100>  // b.none
     f6c:	52800406 	mov	w6, #0x20                  	// #32
     f70:	2a0603e3 	mov	w3, w6
     f74:	4b1603e2 	neg	w2, w22
     f78:	12001ea1 	and	w1, w21, #0xff
     f7c:	2a3603f6 	mvn	w22, w22
     f80:	2a1703e4 	mov	w4, w23
     f84:	0b0302c3 	add	w3, w22, w3
     f88:	2a0103e0 	mov	w0, w1
     f8c:	1ac60847 	udiv	w7, w2, w6
     f90:	52800025 	mov	w5, #0x1                   	// #1
		pr_err_once("unknown opcode %02x\n", code);
     f94:	52800016 	mov	w22, #0x0                   	// #0
		emit(A64_LSL(is64, dst, dst, imm), ctx);
     f98:	1b0688e2 	msub	w2, w7, w6, w2
     f9c:	17ffffe5 	b	f30 <build_insn+0xc30>
		emit(A64_LSR(is64, dst, dst, imm), ctx);
     fa0:	7100143f 	cmp	w1, #0x5
     fa4:	528003e0 	mov	w0, #0x1f                  	// #31
     fa8:	12001ea1 	and	w1, w21, #0xff
     fac:	2a1703e4 	mov	w4, w23
     fb0:	2a1603e2 	mov	w2, w22
     fb4:	528007e3 	mov	w3, #0x3f                  	// #63
     fb8:	52800025 	mov	w5, #0x1                   	// #1
     fbc:	1a800063 	csel	w3, w3, w0, eq  // eq = none
     fc0:	2a0103e0 	mov	w0, w1
     fc4:	94000000 	bl	0 <aarch64_insn_gen_bitfield>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     fc8:	17fffdb4 	b	698 <build_insn+0x398>
	/* function return */
     fcc:	f9404c80 	ldr	x0, [x4, #152]
     fd0:	b9407261 	ldr	w1, [x19, #112]
     fd4:	b9400c00 	ldr	w0, [x0, #12]
     fd8:	51000400 	sub	w0, w0, #0x1
     fdc:	6b01001f 	cmp	w0, w1
     fe0:	54ff9e60 	b.eq	3ac <build_insn+0xac>  // b.none
			/* Set return value */
     fe4:	52800004 	mov	w4, #0x0                   	// #0
     fe8:	52800023 	mov	w3, #0x1                   	// #1
     fec:	52800002 	mov	w2, #0x0                   	// #0
     ff0:	528000e1 	mov	w1, #0x7                   	// #7
     ff4:	52800000 	mov	w0, #0x0                   	// #0
     ff8:	94000000 	bl	0 <aarch64_insn_gen_add_sub_imm>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
     ffc:	39410262 	ldrb	w2, [x19, #64]
			/* Set return value */
    1000:	2a0003e4 	mov	w4, w0
			break;
    1004:	52800041 	mov	w1, #0x2                   	// #2
    1008:	528003c0 	mov	w0, #0x1e                  	// #30
	ctx->bpf2bi_cnt++;
    100c:	11000443 	add	w3, w2, #0x1
		pr_err_once("unknown opcode %02x\n", code);
    1010:	52800016 	mov	w22, #0x0                   	// #0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1014:	b822da64 	str	w4, [x19, w2, sxtw #2]
	ctx->bpf2bi_cnt++;
    1018:	39010263 	strb	w3, [x19, #64]
			break;
    101c:	94000000 	bl	0 <aarch64_insn_gen_branch_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1020:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    1024:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1028:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    102c:	39010262 	strb	w2, [x19, #64]
}
    1030:	17fffcd1 	b	374 <build_insn+0x74>
	{
    1034:	b9800c00 	ldrsw	x0, [x0, #12]
    1038:	2a1603f4 	mov	w20, w22
		emit(A64_MOV(is64, dst, src), ctx);
    103c:	12001eb5 	and	w21, w21, #0xff
	if (!(nrm_tmp >> 32))
    1040:	2a0003e2 	mov	w2, w0
	{
    1044:	aa008294 	orr	x20, x20, x0, lsl #32
	if (!(nrm_tmp >> 32))
    1048:	34004100 	cbz	w0, 1868 <build_insn+0x1568>
	       (((val >> 16) & 0xffff) != (inverse ? 0xffff : 0x0000)) +
    104c:	53107e83 	lsr	w3, w20, #16
    1050:	d29fffe0 	mov	x0, #0xffff                	// #65535
    1054:	eb00007f 	cmp	x3, x0
	       (((val >> 48) & 0xffff) != (inverse ? 0xffff : 0x0000));
    1058:	d370fe84 	lsr	x4, x20, #48
	       (((val >> 16) & 0xffff) != (inverse ? 0xffff : 0x0000)) +
    105c:	1a9f07f7 	cset	w23, ne  // ne = any
	       (((val >> 32) & 0xffff) != (inverse ? 0xffff : 0x0000)) +
    1060:	eb22201f 	cmp	x0, w2, uxth
    1064:	1a9706f7 	cinc	w23, w23, ne  // ne = any
	return (((val >>  0) & 0xffff) != (inverse ? 0xffff : 0x0000)) +
    1068:	eb34201f 	cmp	x0, w20, uxth
    106c:	1a9f07e1 	cset	w1, ne  // ne = any
	       (((val >> 48) & 0xffff) != (inverse ? 0xffff : 0x0000));
    1070:	eb00009f 	cmp	x4, x0
	       (((val >> 32) & 0xffff) != (inverse ? 0xffff : 0x0000)) +
    1074:	1a810421 	cinc	w1, w1, ne  // ne = any
	return (((val >>  0) & 0xffff) != (inverse ? 0xffff : 0x0000)) +
    1078:	72003e9f 	tst	w20, #0xffff
    107c:	1a9f07f8 	cset	w24, ne  // ne = any
	       (((val >> 48) & 0xffff) != (inverse ? 0xffff : 0x0000));
    1080:	f100009f 	cmp	x4, #0x0
	       (((val >> 32) & 0xffff) != (inverse ? 0xffff : 0x0000)) +
    1084:	1a980718 	cinc	w24, w24, ne  // ne = any
	       (((val >> 16) & 0xffff) != (inverse ? 0xffff : 0x0000)) +
    1088:	f100007f 	cmp	x3, #0x0
    108c:	1a9f07e0 	cset	w0, ne  // ne = any
	       (((val >> 32) & 0xffff) != (inverse ? 0xffff : 0x0000)) +
    1090:	72003c5f 	tst	w2, #0xffff
    1094:	1a800400 	cinc	w0, w0, ne  // ne = any
    1098:	0b0102f7 	add	w23, w23, w1
    109c:	0b000318 	add	w24, w24, w0
	shift = max(round_down((inverse ? (fls64(rev_tmp) - 1) :
    10a0:	6b17031f 	cmp	w24, w23
    10a4:	5400364d 	b.le	176c <build_insn+0x146c>
	u64 nrm_tmp = val, rev_tmp = ~val;
    10a8:	aa3403e0 	mvn	x0, x20
	return fls(x);
}
#elif BITS_PER_LONG == 64
static __always_inline int fls64(__u64 x)
{
	if (x == 0)
    10ac:	b40052a0 	cbz	x0, 1b00 <build_insn+0x1800>
 *
 * Undefined if no set bit exists, so code should check against 0 first.
 */
static __always_inline unsigned long __fls(unsigned long word)
{
	return (sizeof(word) * 8) - 1 - __builtin_clzl(word);
    10b0:	dac01001 	clz	x1, x0
    10b4:	d28007e2 	mov	x2, #0x3f                  	// #63
    10b8:	cb010042 	sub	x2, x2, x1
		emit(A64_MOVN(1, reg, (rev_tmp >> shift) & 0xffff, shift), ctx);
    10bc:	52800044 	mov	w4, #0x2                   	// #2
	shift = max(round_down((inverse ? (fls64(rev_tmp) - 1) :
    10c0:	121c6c42 	and	w2, w2, #0xfffffff0
		emit(A64_MOVN(1, reg, (rev_tmp >> shift) & 0xffff, shift), ctx);
    10c4:	52800023 	mov	w3, #0x1                   	// #1
	shift -= 16;
    10c8:	51004056 	sub	w22, w2, #0x10
		emit(A64_MOVN(1, reg, (rev_tmp >> shift) & 0xffff, shift), ctx);
    10cc:	9ac22401 	lsr	x1, x0, x2
    10d0:	2a1503e0 	mov	w0, w21
    10d4:	12003c21 	and	w1, w1, #0xffff
    10d8:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    10dc:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    10e0:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    10e4:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    10e8:	39010262 	strb	w2, [x19, #64]
	while (shift >= 0) {
    10ec:	37f80276 	tbnz	w22, #31, 1138 <build_insn+0xe38>
    10f0:	6b17031f 	cmp	w24, w23
    10f4:	d29ffff7 	mov	x23, #0xffff                	// #65535
    10f8:	9a9fc2f7 	csel	x23, x23, xzr, gt
		if (((nrm_tmp >> shift) & 0xffff) != (inverse ? 0xffff : 0x0000))
    10fc:	9ad62680 	lsr	x0, x20, x22
    1100:	92403c01 	and	x1, x0, #0xffff
    1104:	eb2022ff 	cmp	x23, w0, uxth
    1108:	54000140 	b.eq	1130 <build_insn+0xe30>  // b.none
			emit(A64_MOVK(1, reg, (nrm_tmp >> shift) & 0xffff, shift), ctx);
    110c:	2a1603e2 	mov	w2, w22
    1110:	52800024 	mov	w4, #0x1                   	// #1
    1114:	2a1503e0 	mov	w0, w21
    1118:	2a0403e3 	mov	w3, w4
    111c:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1120:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    1124:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1128:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    112c:	39010262 	strb	w2, [x19, #64]
	while (shift >= 0) {
    1130:	710042d6 	subs	w22, w22, #0x10
    1134:	54fffe45 	b.pl	10fc <build_insn+0xdfc>  // b.nfrst

    1138:	52800036 	mov	w22, #0x1                   	// #1
    113c:	17fffc8e 	b	374 <build_insn+0x74>
		emit(A64_B(jmp_offset), ctx);
    1140:	531e7701 	lsl	w1, w24, #2
    1144:	52800002 	mov	w2, #0x0                   	// #0
    1148:	d2800000 	mov	x0, #0x0                   	// #0
		pr_err_once("unknown opcode %02x\n", code);
    114c:	52800016 	mov	w22, #0x0                   	// #0
		emit(A64_B(jmp_offset), ctx);
    1150:	93407c21 	sxtw	x1, w1
    1154:	94000000 	bl	0 <aarch64_insn_gen_branch_imm>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1158:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    115c:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1160:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    1164:	39010262 	strb	w2, [x19, #64]
}
    1168:	17fffc83 	b	374 <build_insn+0x74>
		if (oinsn->to_jmp) {
    116c:	f9402661 	ldr	x1, [x19, #72]
	emit(A64_MOVN(1, reg, ~tmp & 0xffff, shift), ctx);
    1170:	52800044 	mov	w4, #0x2                   	// #2
    1174:	52800023 	mov	w3, #0x1                   	// #1
    1178:	52800002 	mov	w2, #0x0                   	// #0
    117c:	52800140 	mov	w0, #0xa                   	// #10
		pr_err_once("unknown opcode %02x\n", code);
    1180:	52800016 	mov	w22, #0x0                   	// #0
		if (oinsn->to_jmp) {
    1184:	b9404434 	ldr	w20, [x1, #68]
    1188:	531e7694 	lsl	w20, w20, #2
    118c:	8b070294 	add	x20, x20, x7
	emit(A64_MOVN(1, reg, ~tmp & 0xffff, shift), ctx);
    1190:	2a3403e1 	mvn	w1, w20
    1194:	12003c21 	and	w1, w1, #0xffff
    1198:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    119c:	39410265 	ldrb	w5, [x19, #64]
	emit(A64_MOVN(1, reg, ~tmp & 0xffff, shift), ctx);
    11a0:	2a0003e7 	mov	w7, w0
		emit(A64_MOVK(1, reg, tmp & 0xffff, shift), ctx);
    11a4:	52800024 	mov	w4, #0x1                   	// #1
    11a8:	53107e81 	lsr	w1, w20, #16
	ctx->bpf2bi_cnt++;
    11ac:	0b0400a6 	add	w6, w5, w4
		emit(A64_MOVK(1, reg, tmp & 0xffff, shift), ctx);
    11b0:	2a0403e3 	mov	w3, w4
    11b4:	52800202 	mov	w2, #0x10                  	// #16
    11b8:	52800140 	mov	w0, #0xa                   	// #10
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    11bc:	b825da67 	str	w7, [x19, w5, sxtw #2]
	ctx->bpf2bi_cnt++;
    11c0:	39010266 	strb	w6, [x19, #64]
		emit(A64_MOVK(1, reg, tmp & 0xffff, shift), ctx);
    11c4:	94000000 	bl	0 <aarch64_insn_gen_movewide>
    11c8:	2a0003e7 	mov	w7, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    11cc:	39410265 	ldrb	w5, [x19, #64]
		emit(A64_MOVK(1, reg, tmp & 0xffff, shift), ctx);
    11d0:	52800024 	mov	w4, #0x1                   	// #1
    11d4:	d360be81 	ubfx	x1, x20, #32, #16
    11d8:	2a0403e3 	mov	w3, w4
	ctx->bpf2bi_cnt++;
    11dc:	0b0400a6 	add	w6, w5, w4
		emit(A64_MOVK(1, reg, tmp & 0xffff, shift), ctx);
    11e0:	52800402 	mov	w2, #0x20                  	// #32
    11e4:	52800140 	mov	w0, #0xa                   	// #10
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    11e8:	b825da67 	str	w7, [x19, w5, sxtw #2]
	ctx->bpf2bi_cnt++;
    11ec:	39010266 	strb	w6, [x19, #64]
		emit(A64_MOVK(1, reg, tmp & 0xffff, shift), ctx);
    11f0:	94000000 	bl	0 <aarch64_insn_gen_movewide>
    11f4:	2a0003e4 	mov	w4, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    11f8:	39410262 	ldrb	w2, [x19, #64]
			func_addr = insn->imm;
    11fc:	52800021 	mov	w1, #0x1                   	// #1
    1200:	52800140 	mov	w0, #0xa                   	// #10
	ctx->bpf2bi_cnt++;
    1204:	0b010043 	add	w3, w2, w1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1208:	b822da64 	str	w4, [x19, w2, sxtw #2]
	ctx->bpf2bi_cnt++;
    120c:	39010263 	strb	w3, [x19, #64]
			func_addr = insn->imm;
    1210:	94000000 	bl	0 <aarch64_insn_gen_branch_reg>
    1214:	2a0003e7 	mov	w7, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1218:	39410265 	ldrb	w5, [x19, #64]
		}
    121c:	52800023 	mov	w3, #0x1                   	// #1
    1220:	52800002 	mov	w2, #0x0                   	// #0
    1224:	52800001 	mov	w1, #0x0                   	// #0
	ctx->bpf2bi_cnt++;
    1228:	0b0300a6 	add	w6, w5, w3
		}
    122c:	52800004 	mov	w4, #0x0                   	// #0
    1230:	528000e0 	mov	w0, #0x7                   	// #7
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1234:	b825da67 	str	w7, [x19, w5, sxtw #2]
	ctx->bpf2bi_cnt++;
    1238:	39010266 	strb	w6, [x19, #64]
		}
    123c:	94000000 	bl	0 <aarch64_insn_gen_add_sub_imm>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1240:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    1244:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1248:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    124c:	39010262 	strb	w2, [x19, #64]
}
    1250:	17fffc49 	b	374 <build_insn+0x74>
    1254:	7100401f 	cmp	w0, #0x10
    1258:	54000280 	b.eq	12a8 <build_insn+0xfa8>  // b.none
    125c:	52800102 	mov	w2, #0x8                   	// #8
    1260:	7100801f 	cmp	w0, #0x20
    1264:	54ff8de0 	b.eq	420 <build_insn+0x120>  // b.none
    1268:	128001b6 	mov	w22, #0xfffffff2            	// #-14
    126c:	17fffc42 	b	374 <build_insn+0x74>
    1270:	7103001f 	cmp	w0, #0xc0
    1274:	540005c0 	b.eq	132c <build_insn+0x102c>  // b.none
    1278:	540000a9 	b.ls	128c <build_insn+0xf8c>  // b.plast
    127c:	7103401f 	cmp	w0, #0xd0
    1280:	54ffff41 	b.ne	1268 <build_insn+0xf68>  // b.any
    1284:	528001a2 	mov	w2, #0xd                   	// #13
    1288:	17fffc66 	b	420 <build_insn+0x120>
    128c:	7102801f 	cmp	w0, #0xa0
    1290:	54000100 	b.eq	12b0 <build_insn+0xfb0>  // b.none
    1294:	52800122 	mov	w2, #0x9                   	// #9
    1298:	7102c01f 	cmp	w0, #0xb0
    129c:	54ff8c20 	b.eq	420 <build_insn+0x120>  // b.none
    12a0:	128001b6 	mov	w22, #0xfffffff2            	// #-14
    12a4:	17fffc34 	b	374 <build_insn+0x74>
    12a8:	52800002 	mov	w2, #0x0                   	// #0
    12ac:	17fffc5d 	b	420 <build_insn+0x120>
    12b0:	52800062 	mov	w2, #0x3                   	// #3
    12b4:	17fffc5b 	b	420 <build_insn+0x120>
    12b8:	52800182 	mov	w2, #0xc                   	// #12
    12bc:	17fffc59 	b	420 <build_insn+0x120>
    12c0:	7100635f 	cmp	w26, #0x18
    12c4:	54ff8741 	b.ne	3ac <build_insn+0xac>  // b.any
		case BPF_B:
    12c8:	12001ea1 	and	w1, w21, #0xff
    12cc:	52800024 	mov	w4, #0x1                   	// #1
    12d0:	52800063 	mov	w3, #0x3                   	// #3
    12d4:	52800162 	mov	w2, #0xb                   	// #11
    12d8:	52800140 	mov	w0, #0xa                   	// #10
    12dc:	94000000 	bl	0 <aarch64_insn_gen_load_store_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    12e0:	17fffcee 	b	698 <build_insn+0x398>
    12e4:	7100635f 	cmp	w26, #0x18
    12e8:	54ff8621 	b.ne	3ac <build_insn+0xac>  // b.any
		case BPF_B:
    12ec:	12001ea1 	and	w1, w21, #0xff
    12f0:	12001f20 	and	w0, w25, #0xff
    12f4:	52800024 	mov	w4, #0x1                   	// #1
    12f8:	52800063 	mov	w3, #0x3                   	// #3
    12fc:	52800142 	mov	w2, #0xa                   	// #10
    1300:	94000000 	bl	0 <aarch64_insn_gen_load_store_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1304:	17fffce5 	b	698 <build_insn+0x398>
    1308:	7100635f 	cmp	w26, #0x18
    130c:	54ff8501 	b.ne	3ac <build_insn+0xac>  // b.any
		case BPF_B:
    1310:	12001f21 	and	w1, w25, #0xff
    1314:	12001ea0 	and	w0, w21, #0xff
    1318:	52800004 	mov	w4, #0x0                   	// #0
    131c:	52800063 	mov	w3, #0x3                   	// #3
    1320:	52800142 	mov	w2, #0xa                   	// #10
    1324:	94000000 	bl	0 <aarch64_insn_gen_load_store_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1328:	17fffcdc 	b	698 <build_insn+0x398>
    132c:	52800162 	mov	w2, #0xb                   	// #11
    1330:	17fffc3c 	b	420 <build_insn+0x120>
    1334:	52800042 	mov	w2, #0x2                   	// #2
    1338:	17fffc3a 	b	420 <build_insn+0x120>
		}
    133c:	7100635f 	cmp	w26, #0x18
    1340:	2a1503e1 	mov	w1, w21
    1344:	1a9f17f6 	cset	w22, eq  // eq = none
    1348:	528000c4 	mov	w4, #0x6                   	// #6
    134c:	11000ad4 	add	w20, w22, #0x2
    1350:	528003e2 	mov	w2, #0x1f                  	// #31
    1354:	2a1403e3 	mov	w3, w20
    1358:	52800160 	mov	w0, #0xb                   	// #11
    135c:	94000000 	bl	0 <aarch64_insn_gen_load_store_ex>
    1360:	2a0003e8 	mov	w8, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1364:	39410266 	ldrb	w6, [x19, #64]
		if (cpus_have_cap(ARM64_HAS_LSE_ATOMICS)) {
    1368:	2a1603e4 	mov	w4, w22
    136c:	52800161 	mov	w1, #0xb                   	// #11
    1370:	2a1903e2 	mov	w2, w25
	ctx->bpf2bi_cnt++;
    1374:	110004c7 	add	w7, w6, #0x1
		if (cpus_have_cap(ARM64_HAS_LSE_ATOMICS)) {
    1378:	2a0103e0 	mov	w0, w1
    137c:	52800005 	mov	w5, #0x0                   	// #0
    1380:	52800003 	mov	w3, #0x0                   	// #0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1384:	b826da68 	str	w8, [x19, w6, sxtw #2]
		pr_err_once("unknown opcode %02x\n", code);
    1388:	52800016 	mov	w22, #0x0                   	// #0
	ctx->bpf2bi_cnt++;
    138c:	39010267 	strb	w7, [x19, #64]
		if (cpus_have_cap(ARM64_HAS_LSE_ATOMICS)) {
    1390:	94000000 	bl	0 <aarch64_insn_gen_add_sub_shifted_reg>
    1394:	2a0003e7 	mov	w7, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1398:	39410265 	ldrb	w5, [x19, #64]
			emit(A64_STADD(isdw, reg, src), ctx);
    139c:	2a1403e3 	mov	w3, w20
    13a0:	2a1503e1 	mov	w1, w21
    13a4:	528000e4 	mov	w4, #0x7                   	// #7
	ctx->bpf2bi_cnt++;
    13a8:	110004a6 	add	w6, w5, #0x1
			emit(A64_STADD(isdw, reg, src), ctx);
    13ac:	52800182 	mov	w2, #0xc                   	// #12
    13b0:	52800160 	mov	w0, #0xb                   	// #11
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    13b4:	b825da67 	str	w7, [x19, w5, sxtw #2]
	ctx->bpf2bi_cnt++;
    13b8:	39010266 	strb	w6, [x19, #64]
			emit(A64_STADD(isdw, reg, src), ctx);
    13bc:	94000000 	bl	0 <aarch64_insn_gen_load_store_ex>
    13c0:	2a0003e7 	mov	w7, w0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    13c4:	39410265 	ldrb	w5, [x19, #64]
			emit(A64_ADD(isdw, tmp2, tmp2, src), ctx);
    13c8:	52800182 	mov	w2, #0xc                   	// #12
    13cc:	92800161 	mov	x1, #0xfffffffffffffff4    	// #-12
    13d0:	52800084 	mov	w4, #0x4                   	// #4
	ctx->bpf2bi_cnt++;
    13d4:	110004a6 	add	w6, w5, #0x1
			emit(A64_ADD(isdw, tmp2, tmp2, src), ctx);
    13d8:	52800003 	mov	w3, #0x0                   	// #0
    13dc:	d2800000 	mov	x0, #0x0                   	// #0
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    13e0:	b825da67 	str	w7, [x19, w5, sxtw #2]
	ctx->bpf2bi_cnt++;
    13e4:	39010266 	strb	w6, [x19, #64]
			emit(A64_ADD(isdw, tmp2, tmp2, src), ctx);
    13e8:	94000000 	bl	0 <aarch64_insn_gen_comp_branch_imm>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    13ec:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    13f0:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    13f4:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    13f8:	39010262 	strb	w2, [x19, #64]
}
    13fc:	17fffbde 	b	374 <build_insn+0x74>
    1400:	52800806 	mov	w6, #0x40                  	// #64
		emit(A64_LSL(is64, dst, dst, imm), ctx);
    1404:	2a0603e3 	mov	w3, w6
    1408:	17fffedb 	b	f74 <build_insn+0xc74>
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
    140c:	12003ec1 	and	w1, w22, #0xffff
    1410:	52800002 	mov	w2, #0x0                   	// #0
    1414:	2a1703e3 	mov	w3, w23
    1418:	52800004 	mov	w4, #0x0                   	// #0
    141c:	52800140 	mov	w0, #0xa                   	// #10
    1420:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1424:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    1428:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    142c:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    1430:	39010262 	strb	w2, [x19, #64]
		if (hi)
    1434:	34ffcf14 	cbz	w20, e14 <build_insn+0xb14>
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
    1438:	2a1803e1 	mov	w1, w24
    143c:	2a1703e3 	mov	w3, w23
    1440:	52800024 	mov	w4, #0x1                   	// #1
    1444:	52800202 	mov	w2, #0x10                  	// #16
    1448:	17fffe6d 	b	dfc <build_insn+0xafc>
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
    144c:	12003ec1 	and	w1, w22, #0xffff
    1450:	52800002 	mov	w2, #0x0                   	// #0
    1454:	2a1703e3 	mov	w3, w23
    1458:	2a1503e0 	mov	w0, w21
    145c:	52800004 	mov	w4, #0x0                   	// #0
    1460:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1464:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    1468:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    146c:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    1470:	39010262 	strb	w2, [x19, #64]
		if (hi)
    1474:	34ff79d4 	cbz	w20, 3ac <build_insn+0xac>
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
    1478:	2a1703e3 	mov	w3, w23
    147c:	2a1803e1 	mov	w1, w24
    1480:	2a1503e0 	mov	w0, w21
    1484:	52800024 	mov	w4, #0x1                   	// #1
    1488:	52800202 	mov	w2, #0x10                  	// #16
    148c:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1490:	17fffc82 	b	698 <build_insn+0x398>
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
    1494:	12003ec1 	and	w1, w22, #0xffff
    1498:	52800002 	mov	w2, #0x0                   	// #0
    149c:	2a1703e3 	mov	w3, w23
    14a0:	52800004 	mov	w4, #0x0                   	// #0
    14a4:	52800140 	mov	w0, #0xa                   	// #10
    14a8:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    14ac:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    14b0:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    14b4:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    14b8:	39010262 	strb	w2, [x19, #64]
		if (hi)
    14bc:	34ffcf94 	cbz	w20, eac <build_insn+0xbac>
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
    14c0:	2a1803e1 	mov	w1, w24
    14c4:	2a1703e3 	mov	w3, w23
    14c8:	52800024 	mov	w4, #0x1                   	// #1
    14cc:	52800202 	mov	w2, #0x10                  	// #16
    14d0:	17fffe71 	b	e94 <build_insn+0xb94>
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
    14d4:	12003ec1 	and	w1, w22, #0xffff
    14d8:	52800002 	mov	w2, #0x0                   	// #0
    14dc:	2a1703e3 	mov	w3, w23
    14e0:	52800004 	mov	w4, #0x0                   	// #0
    14e4:	52800140 	mov	w0, #0xa                   	// #10
    14e8:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    14ec:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    14f0:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    14f4:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    14f8:	39010262 	strb	w2, [x19, #64]
		if (hi)
    14fc:	34ff7594 	cbz	w20, 3ac <build_insn+0xac>
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
    1500:	2a1703e3 	mov	w3, w23
    1504:	2a1503e1 	mov	w1, w21
    1508:	52800024 	mov	w4, #0x1                   	// #1
    150c:	52800202 	mov	w2, #0x10                  	// #16
    1510:	52800140 	mov	w0, #0xa                   	// #10
    1514:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1518:	17fffc60 	b	698 <build_insn+0x398>
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
    151c:	12003ec1 	and	w1, w22, #0xffff
    1520:	52800002 	mov	w2, #0x0                   	// #0
    1524:	2a1703e3 	mov	w3, w23
    1528:	52800004 	mov	w4, #0x0                   	// #0
    152c:	52800140 	mov	w0, #0xa                   	// #10
    1530:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1534:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    1538:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    153c:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    1540:	39010262 	strb	w2, [x19, #64]
		if (hi)
    1544:	34ffbc74 	cbz	w20, cd0 <build_insn+0x9d0>
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
    1548:	2a1803e1 	mov	w1, w24
    154c:	2a1703e3 	mov	w3, w23
    1550:	52800024 	mov	w4, #0x1                   	// #1
    1554:	52800202 	mov	w2, #0x10                  	// #16
    1558:	17fffdd8 	b	cb8 <build_insn+0x9b8>
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
    155c:	12003ec1 	and	w1, w22, #0xffff
    1560:	52800002 	mov	w2, #0x0                   	// #0
    1564:	2a1703e3 	mov	w3, w23
    1568:	52800004 	mov	w4, #0x0                   	// #0
    156c:	52800140 	mov	w0, #0xa                   	// #10
    1570:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1574:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    1578:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    157c:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    1580:	39010262 	strb	w2, [x19, #64]
		if (hi)
    1584:	34ffa654 	cbz	w20, a4c <build_insn+0x74c>
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
    1588:	2a1803e1 	mov	w1, w24
    158c:	2a1703e3 	mov	w3, w23
    1590:	52800024 	mov	w4, #0x1                   	// #1
    1594:	52800202 	mov	w2, #0x10                  	// #16
    1598:	17fffd27 	b	a34 <build_insn+0x734>
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
    159c:	12003ec1 	and	w1, w22, #0xffff
    15a0:	52800002 	mov	w2, #0x0                   	// #0
    15a4:	52800004 	mov	w4, #0x0                   	// #0
    15a8:	52800023 	mov	w3, #0x1                   	// #1
    15ac:	52800140 	mov	w0, #0xa                   	// #10
    15b0:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    15b4:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    15b8:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    15bc:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    15c0:	39010262 	strb	w2, [x19, #64]
		if (hi)
    15c4:	34ff8214 	cbz	w20, 604 <build_insn+0x304>
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
    15c8:	2a1703e1 	mov	w1, w23
    15cc:	52800024 	mov	w4, #0x1                   	// #1
    15d0:	52800202 	mov	w2, #0x10                  	// #16
    15d4:	17fffc05 	b	5e8 <build_insn+0x2e8>
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
    15d8:	2a1803e1 	mov	w1, w24
    15dc:	52800004 	mov	w4, #0x0                   	// #0
    15e0:	17fffbe3 	b	56c <build_insn+0x26c>
    15e4:	2a1803e1 	mov	w1, w24
    15e8:	52800004 	mov	w4, #0x0                   	// #0
    15ec:	17fffc3b 	b	6d8 <build_insn+0x3d8>
    15f0:	12003ec1 	and	w1, w22, #0xffff
    15f4:	52800002 	mov	w2, #0x0                   	// #0
    15f8:	2a1703e3 	mov	w3, w23
    15fc:	52800004 	mov	w4, #0x0                   	// #0
    1600:	52800140 	mov	w0, #0xa                   	// #10
    1604:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1608:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    160c:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1610:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    1614:	39010262 	strb	w2, [x19, #64]
		if (hi)
    1618:	34ff9bf4 	cbz	w20, 994 <build_insn+0x694>
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
    161c:	2a1803e1 	mov	w1, w24
    1620:	2a1703e3 	mov	w3, w23
    1624:	52800024 	mov	w4, #0x1                   	// #1
    1628:	52800202 	mov	w2, #0x10                  	// #16
    162c:	17fffcd4 	b	97c <build_insn+0x67c>
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
    1630:	12003ec1 	and	w1, w22, #0xffff
    1634:	52800002 	mov	w2, #0x0                   	// #0
    1638:	2a1703e3 	mov	w3, w23
    163c:	52800004 	mov	w4, #0x0                   	// #0
    1640:	52800160 	mov	w0, #0xb                   	// #11
    1644:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1648:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    164c:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1650:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    1654:	39010262 	strb	w2, [x19, #64]
		if (hi)
    1658:	34ff90d4 	cbz	w20, 870 <build_insn+0x570>
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
    165c:	2a1803e1 	mov	w1, w24
    1660:	2a1703e3 	mov	w3, w23
    1664:	52800024 	mov	w4, #0x1                   	// #1
    1668:	52800202 	mov	w2, #0x10                  	// #16
    166c:	17fffc7b 	b	858 <build_insn+0x558>
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
    1670:	2a1803e1 	mov	w1, w24
    1674:	52800004 	mov	w4, #0x0                   	// #0
    1678:	17fffbf4 	b	648 <build_insn+0x348>
    167c:	12003ec1 	and	w1, w22, #0xffff
    1680:	52800002 	mov	w2, #0x0                   	// #0
    1684:	2a1703e3 	mov	w3, w23
    1688:	52800004 	mov	w4, #0x0                   	// #0
    168c:	52800140 	mov	w0, #0xa                   	// #10
    1690:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1694:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    1698:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    169c:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    16a0:	39010262 	strb	w2, [x19, #64]
		if (hi)
    16a4:	34ffa4d9 	cbz	w25, b3c <build_insn+0x83c>
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
    16a8:	2a1a03e1 	mov	w1, w26
    16ac:	52800202 	mov	w2, #0x10                  	// #16
    16b0:	2a1703e3 	mov	w3, w23
    16b4:	52800024 	mov	w4, #0x1                   	// #1
    16b8:	52800140 	mov	w0, #0xa                   	// #10
    16bc:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    16c0:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    16c4:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    16c8:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    16cc:	39010262 	strb	w2, [x19, #64]
}
    16d0:	17fffd1b 	b	b3c <build_insn+0x83c>
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
    16d4:	12003ec1 	and	w1, w22, #0xffff
    16d8:	52800002 	mov	w2, #0x0                   	// #0
    16dc:	2a1703e3 	mov	w3, w23
    16e0:	52800004 	mov	w4, #0x0                   	// #0
    16e4:	52800140 	mov	w0, #0xa                   	// #10
    16e8:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    16ec:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    16f0:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    16f4:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    16f8:	39010262 	strb	w2, [x19, #64]
		if (hi)
    16fc:	34ff8634 	cbz	w20, 7c0 <build_insn+0x4c0>
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
    1700:	2a1803e1 	mov	w1, w24
    1704:	2a1703e3 	mov	w3, w23
    1708:	52800024 	mov	w4, #0x1                   	// #1
    170c:	52800202 	mov	w2, #0x10                  	// #16
    1710:	17fffc26 	b	7a8 <build_insn+0x4a8>
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
    1714:	12003ec1 	and	w1, w22, #0xffff
    1718:	52800002 	mov	w2, #0x0                   	// #0
    171c:	2a1703e3 	mov	w3, w23
    1720:	52800004 	mov	w4, #0x0                   	// #0
    1724:	52800140 	mov	w0, #0xa                   	// #10
    1728:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    172c:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    1730:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1734:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    1738:	39010262 	strb	w2, [x19, #64]
		if (hi)
    173c:	34ff6c79 	cbz	w25, 4c8 <build_insn+0x1c8>
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
    1740:	2a1a03e1 	mov	w1, w26
    1744:	52800202 	mov	w2, #0x10                  	// #16
    1748:	2a1703e3 	mov	w3, w23
    174c:	52800024 	mov	w4, #0x1                   	// #1
    1750:	52800140 	mov	w0, #0xa                   	// #10
    1754:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1758:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    175c:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1760:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    1764:	39010262 	strb	w2, [x19, #64]
}
    1768:	17fffb58 	b	4c8 <build_insn+0x1c8>
    176c:	dac01280 	clz	x0, x20
    1770:	d28007f6 	mov	x22, #0x3f                  	// #63
    1774:	cb0002d6 	sub	x22, x22, x0
		emit(A64_MOVZ(1, reg, (nrm_tmp >> shift) & 0xffff, shift), ctx);
    1778:	52800004 	mov	w4, #0x0                   	// #0
	shift = max(round_down((inverse ? (fls64(rev_tmp) - 1) :
    177c:	121c6ed6 	and	w22, w22, #0xfffffff0
		emit(A64_MOVZ(1, reg, (nrm_tmp >> shift) & 0xffff, shift), ctx);
    1780:	2a1503e0 	mov	w0, w21
    1784:	2a1603e2 	mov	w2, w22
    1788:	52800023 	mov	w3, #0x1                   	// #1
    178c:	9ad62681 	lsr	x1, x20, x22
    1790:	12003c21 	and	w1, w1, #0xffff
    1794:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	shift -= 16;
    1798:	510042d6 	sub	w22, w22, #0x10
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    179c:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    17a0:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    17a4:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    17a8:	39010262 	strb	w2, [x19, #64]
	while (shift >= 0) {
    17ac:	17fffe51 	b	10f0 <build_insn+0xdf0>
    17b0:	52800142 	mov	w2, #0xa                   	// #10
    17b4:	17fffb1b 	b	420 <build_insn+0x120>
		switch (imm) {
    17b8:	710042df 	cmp	w22, #0x10
    17bc:	54001ba0 	b.eq	1b30 <build_insn+0x1830>  // b.none
    17c0:	710082df 	cmp	w22, #0x20
    17c4:	54ff5f41 	b.ne	3ac <build_insn+0xac>  // b.any
			emit(A64_UXTW(is64, dst, dst), ctx);
    17c8:	12001ea1 	and	w1, w21, #0xff
    17cc:	2a1703e4 	mov	w4, w23
    17d0:	2a0103e0 	mov	w0, w1
    17d4:	52800025 	mov	w5, #0x1                   	// #1
    17d8:	528003e3 	mov	w3, #0x1f                  	// #31
    17dc:	52800002 	mov	w2, #0x0                   	// #0
    17e0:	94000000 	bl	0 <aarch64_insn_gen_bitfield>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    17e4:	17fffbad 	b	698 <build_insn+0x398>
			emit(A64_UDIV(is64, dst, dst, src), ctx);
    17e8:	12001ea1 	and	w1, w21, #0xff
    17ec:	2a1703e3 	mov	w3, w23
    17f0:	12001f22 	and	w2, w25, #0xff
    17f4:	2a0103e0 	mov	w0, w1
    17f8:	52800004 	mov	w4, #0x0                   	// #0
    17fc:	94000000 	bl	0 <aarch64_insn_gen_data2>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1800:	17fffba6 	b	698 <build_insn+0x398>
	if (hi & 0x8000) {
    1804:	36f81798 	tbz	w24, #31, 1af4 <build_insn+0x17f4>
			emit(A64_MOVN(is64, reg, (u16)~lo, 0), ctx);
    1808:	2a3803e1 	mvn	w1, w24
    180c:	52800044 	mov	w4, #0x2                   	// #2
    1810:	12003c21 	and	w1, w1, #0xffff
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
    1814:	52800023 	mov	w3, #0x1                   	// #1
    1818:	52800002 	mov	w2, #0x0                   	// #0
    181c:	52800140 	mov	w0, #0xa                   	// #10
    1820:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1824:	39410261 	ldrb	w1, [x19, #64]
		if (!off) {
    1828:	52800005 	mov	w5, #0x0                   	// #0
    182c:	52800024 	mov	w4, #0x1                   	// #1
    1830:	52800003 	mov	w3, #0x0                   	// #0
	ctx->bpf2bi_cnt++;
    1834:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1838:	b821da60 	str	w0, [x19, w1, sxtw #2]
		if (!off) {
    183c:	52800141 	mov	w1, #0xa                   	// #10
	ctx->bpf2bi_cnt++;
    1840:	39010262 	strb	w2, [x19, #64]
		if (!off) {
    1844:	2a0103e0 	mov	w0, w1
    1848:	12001ea2 	and	w2, w21, #0xff
	ctx->bpf2bi_cnt++;
    184c:	52800155 	mov	w21, #0xa                   	// #10
		if (!off) {
    1850:	94000000 	bl	0 <aarch64_insn_gen_add_sub_shifted_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1854:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    1858:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    185c:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    1860:	39010262 	strb	w2, [x19, #64]
			reg = dst;
    1864:	17fffce4 	b	bf4 <build_insn+0x8f4>
	u16 hi = val >> 16;
    1868:	13107e97 	asr	w23, w20, #16
    186c:	53107e96 	lsr	w22, w20, #16
	if (hi & 0x8000) {
    1870:	36f81714 	tbz	w20, #31, 1b50 <build_insn+0x1850>
	u16 lo = val & 0xffff;
    1874:	12003e98 	and	w24, w20, #0xffff
		if (hi == 0xffff) {
    1878:	529ffff7 	mov	w23, #0xffff                	// #65535
    187c:	6b1702df 	cmp	w22, w23
    1880:	540018a0 	b.eq	1b94 <build_insn+0x1894>  // b.none
			emit(A64_MOVN(is64, reg, (u16)~hi, 16), ctx);
    1884:	2a3603e1 	mvn	w1, w22
    1888:	52800202 	mov	w2, #0x10                  	// #16
    188c:	12003c21 	and	w1, w1, #0xffff
    1890:	2a1503e0 	mov	w0, w21
    1894:	52800044 	mov	w4, #0x2                   	// #2
    1898:	52800003 	mov	w3, #0x0                   	// #0
    189c:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    18a0:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    18a4:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    18a8:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    18ac:	39010262 	strb	w2, [x19, #64]
			if (lo != 0xffff)
    18b0:	6b17031f 	cmp	w24, w23
    18b4:	54ffc420 	b.eq	1138 <build_insn+0xe38>  // b.none
				emit(A64_MOVK(is64, reg, lo, 0), ctx);
    18b8:	12003e81 	and	w1, w20, #0xffff
    18bc:	2a1503e0 	mov	w0, w21
    18c0:	52800024 	mov	w4, #0x1                   	// #1
    18c4:	52800003 	mov	w3, #0x0                   	// #0
    18c8:	52800002 	mov	w2, #0x0                   	// #0
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
    18cc:	94000000 	bl	0 <aarch64_insn_gen_movewide>

    18d0:	52800036 	mov	w22, #0x1                   	// #1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    18d4:	39410262 	ldrb	w2, [x19, #64]
    18d8:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    18dc:	0b160021 	add	w1, w1, w22
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    18e0:	b8227a60 	str	w0, [x19, x2, lsl #2]
	ctx->bpf2bi_cnt++;
    18e4:	39010261 	strb	w1, [x19, #64]
}
    18e8:	17fffaa3 	b	374 <build_insn+0x74>
    18ec:	f9402bfb 	ldr	x27, [sp, #80]
    18f0:	17fffc93 	b	b3c <build_insn+0x83c>
			emit(A64_MOVN(is64, reg, (u16)~lo, 0), ctx);
    18f4:	2a3903e1 	mvn	w1, w25
    18f8:	2a1703e3 	mov	w3, w23
    18fc:	12003c21 	and	w1, w1, #0xffff
    1900:	52800044 	mov	w4, #0x2                   	// #2
    1904:	52800002 	mov	w2, #0x0                   	// #0
    1908:	17fffba8 	b	7a8 <build_insn+0x4a8>
    190c:	2a3b03e1 	mvn	w1, w27
    1910:	52800044 	mov	w4, #0x2                   	// #2
    1914:	12003c21 	and	w1, w1, #0xffff
    1918:	17fffae3 	b	4a4 <build_insn+0x1a4>
    191c:	2a3903e1 	mvn	w1, w25
    1920:	2a1703e3 	mov	w3, w23
    1924:	12003c21 	and	w1, w1, #0xffff
    1928:	52800044 	mov	w4, #0x2                   	// #2
    192c:	52800002 	mov	w2, #0x0                   	// #0
    1930:	17fffc13 	b	97c <build_insn+0x67c>
    1934:	2a3903e1 	mvn	w1, w25
    1938:	2a1703e3 	mov	w3, w23
    193c:	12003c21 	and	w1, w1, #0xffff
    1940:	52800044 	mov	w4, #0x2                   	// #2
    1944:	52800002 	mov	w2, #0x0                   	// #0
    1948:	17fffbc4 	b	858 <build_insn+0x558>
		case BPF_H:
    194c:	12001ea1 	and	w1, w21, #0xff
    1950:	12001f20 	and	w0, w25, #0xff
    1954:	52800024 	mov	w4, #0x1                   	// #1
    1958:	52800003 	mov	w3, #0x0                   	// #0
    195c:	52800142 	mov	w2, #0xa                   	// #10
    1960:	94000000 	bl	0 <aarch64_insn_gen_load_store_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1964:	17fffb4d 	b	698 <build_insn+0x398>
			emit(A64_MOVN(is64, reg, (u16)~lo, 0), ctx);
    1968:	2a3b03e1 	mvn	w1, w27
    196c:	52800044 	mov	w4, #0x2                   	// #2
    1970:	12003c21 	and	w1, w1, #0xffff
    1974:	17fffc69 	b	b18 <build_insn+0x818>
    1978:	2a3903e1 	mvn	w1, w25
    197c:	2a1703e3 	mov	w3, w23
    1980:	12003c21 	and	w1, w1, #0xffff
    1984:	52800044 	mov	w4, #0x2                   	// #2
    1988:	52800002 	mov	w2, #0x0                   	// #0
    198c:	17fffd1c 	b	dfc <build_insn+0xafc>
    1990:	2a3903e1 	mvn	w1, w25
    1994:	2a1703e3 	mov	w3, w23
    1998:	12003c21 	and	w1, w1, #0xffff
    199c:	52800044 	mov	w4, #0x2                   	// #2
    19a0:	52800002 	mov	w2, #0x0                   	// #0
    19a4:	17fffcc5 	b	cb8 <build_insn+0x9b8>
    19a8:	2a3903e1 	mvn	w1, w25
    19ac:	2a1703e3 	mov	w3, w23
    19b0:	12003c21 	and	w1, w1, #0xffff
    19b4:	2a1503e0 	mov	w0, w21
    19b8:	52800044 	mov	w4, #0x2                   	// #2
    19bc:	52800002 	mov	w2, #0x0                   	// #0
    19c0:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    19c4:	17fffb35 	b	698 <build_insn+0x398>
			emit(A64_MOVN(is64, reg, (u16)~lo, 0), ctx);
    19c8:	2a3903e1 	mvn	w1, w25
    19cc:	2a1703e3 	mov	w3, w23
    19d0:	12003c21 	and	w1, w1, #0xffff
    19d4:	52800044 	mov	w4, #0x2                   	// #2
    19d8:	52800002 	mov	w2, #0x0                   	// #0
    19dc:	17fffd2e 	b	e94 <build_insn+0xb94>
    19e0:	2a3903e1 	mvn	w1, w25
    19e4:	2a1703e3 	mov	w3, w23
    19e8:	12003c21 	and	w1, w1, #0xffff
    19ec:	52800044 	mov	w4, #0x2                   	// #2
    19f0:	52800002 	mov	w2, #0x0                   	// #0
    19f4:	17fffc10 	b	a34 <build_insn+0x734>
		case BPF_H:
    19f8:	12001f21 	and	w1, w25, #0xff
    19fc:	12001ea0 	and	w0, w21, #0xff
    1a00:	52800004 	mov	w4, #0x0                   	// #0
    1a04:	52800003 	mov	w3, #0x0                   	// #0
    1a08:	52800142 	mov	w2, #0xa                   	// #10
    1a0c:	94000000 	bl	0 <aarch64_insn_gen_load_store_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1a10:	17fffb22 	b	698 <build_insn+0x398>
	case BPF_STX | BPF_MEM | BPF_DW:
    1a14:	12001ea1 	and	w1, w21, #0xff
    1a18:	12001f20 	and	w0, w25, #0xff
    1a1c:	52800024 	mov	w4, #0x1                   	// #1
    1a20:	52800043 	mov	w3, #0x2                   	// #2
    1a24:	52800142 	mov	w2, #0xa                   	// #10
    1a28:	94000000 	bl	0 <aarch64_insn_gen_load_store_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1a2c:	17fffb1b 	b	698 <build_insn+0x398>
	case BPF_LDX | BPF_MEM | BPF_DW:
    1a30:	12001f21 	and	w1, w25, #0xff
    1a34:	12001ea0 	and	w0, w21, #0xff
    1a38:	52800004 	mov	w4, #0x0                   	// #0
    1a3c:	52800043 	mov	w3, #0x2                   	// #2
    1a40:	52800142 	mov	w2, #0xa                   	// #10
    1a44:	94000000 	bl	0 <aarch64_insn_gen_load_store_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1a48:	17fffb14 	b	698 <build_insn+0x398>
			emit(A64_MOVN(is64, reg, (u16)~lo, 0), ctx);
    1a4c:	2a3803e1 	mvn	w1, w24
    1a50:	2a1703e3 	mov	w3, w23
    1a54:	12003c21 	and	w1, w1, #0xffff
    1a58:	52800044 	mov	w4, #0x2                   	// #2
    1a5c:	52800002 	mov	w2, #0x0                   	// #0
    1a60:	52800140 	mov	w0, #0xa                   	// #10
    1a64:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1a68:	17fffb0c 	b	698 <build_insn+0x398>
    1a6c:	f9402bfb 	ldr	x27, [sp, #80]
    1a70:	17fffa96 	b	4c8 <build_insn+0x1c8>
			emit(A64_MOVN(is64, reg, (u16)~lo, 0), ctx);
    1a74:	2a3803e1 	mvn	w1, w24
    1a78:	52800044 	mov	w4, #0x2                   	// #2
    1a7c:	12003c21 	and	w1, w1, #0xffff
    1a80:	52800023 	mov	w3, #0x1                   	// #1
    1a84:	52800002 	mov	w2, #0x0                   	// #0
    1a88:	17fffad9 	b	5ec <build_insn+0x2ec>
		case BPF_H:
    1a8c:	12001ea1 	and	w1, w21, #0xff
    1a90:	52800024 	mov	w4, #0x1                   	// #1
    1a94:	52800003 	mov	w3, #0x0                   	// #0
    1a98:	52800162 	mov	w2, #0xb                   	// #11
    1a9c:	52800140 	mov	w0, #0xa                   	// #10
    1aa0:	94000000 	bl	0 <aarch64_insn_gen_load_store_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1aa4:	17fffafd 	b	698 <build_insn+0x398>
		emit_a64_mov_i(1, tmp2, off, ctx);
    1aa8:	12001ea1 	and	w1, w21, #0xff
    1aac:	52800024 	mov	w4, #0x1                   	// #1
    1ab0:	52800043 	mov	w3, #0x2                   	// #2
    1ab4:	52800162 	mov	w2, #0xb                   	// #11
    1ab8:	52800140 	mov	w0, #0xa                   	// #10
    1abc:	94000000 	bl	0 <aarch64_insn_gen_load_store_reg>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1ac0:	17fffaf6 	b	698 <build_insn+0x398>
			emit(A64_REV64(dst, dst), ctx);
    1ac4:	12001ea1 	and	w1, w21, #0xff
    1ac8:	52800043 	mov	w3, #0x2                   	// #2
    1acc:	2a0103e0 	mov	w0, w1
    1ad0:	52800022 	mov	w2, #0x1                   	// #1
    1ad4:	94000000 	bl	0 <aarch64_insn_gen_data1>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1ad8:	17fffaf0 	b	698 <build_insn+0x398>
			emit(A64_REV32(is64, dst, dst), ctx);
    1adc:	12001ea1 	and	w1, w21, #0xff
    1ae0:	2a1703e2 	mov	w2, w23
    1ae4:	2a0103e0 	mov	w0, w1
    1ae8:	52800023 	mov	w3, #0x1                   	// #1
    1aec:	94000000 	bl	0 <aarch64_insn_gen_data1>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1af0:	17fffaea 	b	698 <build_insn+0x398>
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
    1af4:	2a1803e1 	mov	w1, w24
    1af8:	52800004 	mov	w4, #0x0                   	// #0
    1afc:	17ffff46 	b	1814 <build_insn+0x1514>
		emit(A64_MOVN(1, reg, (rev_tmp >> shift) & 0xffff, shift), ctx);
    1b00:	52800002 	mov	w2, #0x0                   	// #0
    1b04:	52800001 	mov	w1, #0x0                   	// #0
    1b08:	2a1503e0 	mov	w0, w21
    1b0c:	52800044 	mov	w4, #0x2                   	// #2
    1b10:	52800023 	mov	w3, #0x1                   	// #1
    1b14:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1b18:	39410261 	ldrb	w1, [x19, #64]

    1b1c:	52800036 	mov	w22, #0x1                   	// #1
	ctx->bpf2bi_cnt++;
    1b20:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1b24:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    1b28:	39010262 	strb	w2, [x19, #64]
	while (shift >= 0) {
    1b2c:	17fffa12 	b	374 <build_insn+0x74>
			emit(A64_UXTH(is64, dst, dst), ctx);
    1b30:	12001ea1 	and	w1, w21, #0xff
    1b34:	2a1703e4 	mov	w4, w23
    1b38:	2a0103e0 	mov	w0, w1
    1b3c:	52800025 	mov	w5, #0x1                   	// #1
    1b40:	528001e3 	mov	w3, #0xf                   	// #15
    1b44:	52800002 	mov	w2, #0x0                   	// #0
    1b48:	94000000 	bl	0 <aarch64_insn_gen_bitfield>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1b4c:	17fffad3 	b	698 <build_insn+0x398>
		emit(A64_MOVZ(is64, reg, lo, 0), ctx);
    1b50:	12003e81 	and	w1, w20, #0xffff
    1b54:	52800002 	mov	w2, #0x0                   	// #0
    1b58:	2a1503e0 	mov	w0, w21
    1b5c:	52800004 	mov	w4, #0x0                   	// #0
    1b60:	52800003 	mov	w3, #0x0                   	// #0
    1b64:	94000000 	bl	0 <aarch64_insn_gen_movewide>
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1b68:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    1b6c:	11000422 	add	w2, w1, #0x1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1b70:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    1b74:	39010262 	strb	w2, [x19, #64]
		if (hi)
    1b78:	34ffae16 	cbz	w22, 1138 <build_insn+0xe38>
			emit(A64_MOVK(is64, reg, hi, 16), ctx);
    1b7c:	2a1703e1 	mov	w1, w23
    1b80:	2a1503e0 	mov	w0, w21
    1b84:	52800024 	mov	w4, #0x1                   	// #1
    1b88:	52800003 	mov	w3, #0x0                   	// #0
    1b8c:	52800202 	mov	w2, #0x10                  	// #16
    1b90:	17ffff4f 	b	18cc <build_insn+0x15cc>
			emit(A64_MOVN(is64, reg, (u16)~lo, 0), ctx);
    1b94:	2a3803e1 	mvn	w1, w24
    1b98:	52800002 	mov	w2, #0x0                   	// #0
    1b9c:	12003c21 	and	w1, w1, #0xffff
    1ba0:	2a1503e0 	mov	w0, w21
    1ba4:	52800044 	mov	w4, #0x2                   	// #2
    1ba8:	52800003 	mov	w3, #0x0                   	// #0
    1bac:	94000000 	bl	0 <aarch64_insn_gen_movewide>

    1bb0:	52800036 	mov	w22, #0x1                   	// #1
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1bb4:	39410261 	ldrb	w1, [x19, #64]
	ctx->bpf2bi_cnt++;
    1bb8:	0b160022 	add	w2, w1, w22
	ctx->bi[ctx->bpf2bi_cnt] = cpu_to_le32(insn);
    1bbc:	b821da60 	str	w0, [x19, w1, sxtw #2]
	ctx->bpf2bi_cnt++;
    1bc0:	39010262 	strb	w2, [x19, #64]
}
    1bc4:	17fff9ec 	b	374 <build_insn+0x74>
		}
    1bc8:	52800023 	mov	w3, #0x1                   	// #1
    1bcc:	2a1403e1 	mov	w1, w20
    1bd0:	90000000 	adrp	x0, 0 <build_prologue>
    1bd4:	39000043 	strb	w3, [x2]
    1bd8:	91000000 	add	x0, x0, #0x0
    1bdc:	94000000 	bl	0 <printk>
    1be0:	17fff9e5 	b	374 <build_insn+0x74>
